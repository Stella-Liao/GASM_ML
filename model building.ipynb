{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "\n",
    "#!pip install spint\n",
    "\n",
    "\n",
    "from spint import Gravity\n",
    "from spint import Production \n",
    "from spint import Attraction \n",
    "from spint import Doubly\n",
    "\n",
    "#!pip install pygam\n",
    "import pygam\n",
    "from pygam import PoissonGAM, s, te, l, f\n",
    "from pygam.core import Core, nice_repr\n",
    "from pygam.utils import isiterable, check_param, flatten, gen_edge_knots, b_spline_basis, tensor_product\n",
    "from pygam.penalties import PENALTIES, CONSTRAINTS\n",
    "from pygam import terms\n",
    "from pygam.terms import Term, LinearTerm\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, PoissonRegressor\n",
    "\n",
    "#!pip install statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools import add_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Data</th>\n",
       "      <th>Oi</th>\n",
       "      <th>Dj</th>\n",
       "      <th>Dij</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AT11</td>\n",
       "      <td>AT11</td>\n",
       "      <td>0</td>\n",
       "      <td>4016</td>\n",
       "      <td>5146</td>\n",
       "      <td>1.000000e-300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AT11</td>\n",
       "      <td>AT12</td>\n",
       "      <td>1131</td>\n",
       "      <td>4016</td>\n",
       "      <td>25741</td>\n",
       "      <td>1.030018e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AT11</td>\n",
       "      <td>AT13</td>\n",
       "      <td>1887</td>\n",
       "      <td>4016</td>\n",
       "      <td>26980</td>\n",
       "      <td>8.420467e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AT11</td>\n",
       "      <td>AT21</td>\n",
       "      <td>69</td>\n",
       "      <td>4016</td>\n",
       "      <td>4117</td>\n",
       "      <td>2.208119e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AT11</td>\n",
       "      <td>AT22</td>\n",
       "      <td>738</td>\n",
       "      <td>4016</td>\n",
       "      <td>8634</td>\n",
       "      <td>1.320075e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Origin Destination  Data    Oi     Dj            Dij\n",
       "0           0   AT11        AT11     0  4016   5146  1.000000e-300\n",
       "1           1   AT11        AT12  1131  4016  25741   1.030018e+02\n",
       "2           2   AT11        AT13  1887  4016  26980   8.420467e+01\n",
       "3           3   AT11        AT21    69  4016   4117   2.208119e+02\n",
       "4           4   AT11        AT22   738  4016   8634   1.320075e+02"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austria_shp = gp.read_file('Data/austria.shp')\n",
    "austria_shp.plot()\n",
    "austria = pd.read_csv('Data/austria.csv')\n",
    "austria.head()#81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the data into arrays.\n",
    "austria = austria[austria['Origin'] != austria['Destination']] #intra-zonal ﬂows have been excluded\n",
    "flows = austria['Data'].values #the number of ﬂows between i and j\n",
    "Oi = austria['Oi'].values \n",
    "Dj = austria['Dj'].values \n",
    "Dij = austria['Dij'].values \n",
    "Origin = austria['Origin'].values \n",
    "Destination = austria['Destination'].values\n",
    "\n",
    "ln_Oi = np.log(austria['Oi'].values) #emissiveness of origin\n",
    "ln_Wj = np.log(austria['Dj'].values) #attraction of destination\n",
    "ln_Dij = np.log( austria['Dij'].values) #distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unconstrained gravity model\n",
    "gravity = Gravity(flows, Oi, Dj, Dij, 'pow') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.85755469,  0.70317833,  0.7376105 , -1.05939577])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gravity.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Backfitting GAM and PoissonGAM with Golden Selection Search in CD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate the Aij and AIC values given a sigma value\n",
    "def aic_func(sigma):\n",
    "    \n",
    "    #calculate the Aij\n",
    "    Aj = sum(Dj* (Dij**sigma))\n",
    "    Aij = Aj - Dj* (Dij**sigma)\n",
    "    ln_Aij = np.log(Aij)\n",
    "    X = sm.add_constant(np.column_stack((ln_Oi, ln_Wj, ln_Dij, ln_Aij)))# so that the glm will estimate a constant\n",
    "    \n",
    "    #fit the model\n",
    "    mod = OLS(flows, X).fit()#sm.GLM(flows, X, family=sm.families.Poisson(),).fit()\n",
    "     \n",
    "    #result dictonary\n",
    "    result_dict = dict()\n",
    "    result_dict['beta'] = mod.params[2]\n",
    "    result_dict['delta'] = mod.params[3]\n",
    "    result_dict['aic'] = mod.aic\n",
    "    result_dict['partial_ress_beta'] = sum(flows - np.mean(flows)- mod.params[0] - mod.params[1]*ln_Oi-mod.params[2]*ln_Wj-mod.params[4]*ln_Aij)\n",
    "    result_dict['partial_ress_delta'] = sum(flows - np.mean(flows) - mod.params[0]- mod.params[1]*ln_Oi-mod.params[2]*ln_Wj-mod.params[3]*ln_Dij) \n",
    "    #result_dict['mod'] = mod\n",
    "\n",
    "    return result_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use golden search method with AIC and partial residuals as the criterion\n",
    "# refer to the codes from search.py to implement golden search\n",
    "\n",
    "# initilize the sigma values given the min and max value of sigma\n",
    "sigma_a = -10 # the initilized MIN value of sigma\n",
    "sigma_c = 5 # the initilized MAX value of sigma\n",
    "step = 1 - 0.618 # following the book so far\n",
    "sigma_b = sigma_a + step * np.abs(sigma_c - sigma_a)\n",
    "sigma_d = sigma_c - step * np.abs(sigma_c - sigma_a)\n",
    "    \n",
    "#other initilization\n",
    "tol = 1e-8 # a thereshold to decide whether f(d) = aic_func(d) stops changing\n",
    "diff = np.inf # store the diff between different f(d)\n",
    "opt_aic = np.inf # store the AIC value based on the optimal sigma value\n",
    "aic_sigma_dict = dict() # store the sigma value and the aic value correpsondingly\n",
    "\n",
    "#temporarily not consider the situation where we can't converge eventually\n",
    "#max_iter = 100 \n",
    "#iters = 0 \n",
    "\n",
    "ptrs_beta0 = 0\n",
    "ptrs_delta0 = 0\n",
    "ptrs_beta_list = []\n",
    "ptrs_delta_list = []\n",
    "ptrs_beta_list.append(ptrs_beta0) # store all partial resdiduals\n",
    "ptrs_delta_list.append(ptrs_delta0)\n",
    "\n",
    "while (diff > tol or diff_b > tol or diff_d > tol) :# and (iters <= max_iter)\n",
    "\n",
    "    aic_b = aic_func(sigma_b)['aic']\n",
    "    aic_d = aic_func(sigma_d)['aic']\n",
    "            \n",
    "    if aic_b <= aic_d: #discard the old c, b<d<c\n",
    "        opt_sigma = sigma_b\n",
    "        sigma_c = sigma_d\n",
    "        sigma_d = sigma_b\n",
    "        sigma_b = sigma_a + step * np.abs(sigma_c - sigma_a)\n",
    "            \n",
    "\n",
    "    else: # discard the old a, a<b<d\n",
    "        opt_sigma = sigma_d\n",
    "        sigma_a = sigma_b\n",
    "        sigma_b = sigma_d\n",
    "        sigma_d = sigma_c - step * np.abs(sigma_c - sigma_a)\n",
    "                   \n",
    "    opt_sigma = np.round(opt_sigma, 3) \n",
    "        \n",
    "    # the aic_b stores the last aic_d so the diff is the difference between the two successive values of f(d)\n",
    "    diff = np.abs(aic_b - aic_d)\n",
    "    \n",
    "    ptrs_beta_list.append(aic_func(opt_sigma)['partial_ress_beta'])\n",
    "    ptrs_delta_list.append(aic_func(opt_sigma)['partial_ress_delta'])\n",
    "    \n",
    "    diff_b = np.abs(ptrs_beta_list[-1] - ptrs_beta_list[-2])\n",
    "    diff_d = np.abs(ptrs_delta_list[-1] - ptrs_delta_list[-2])\n",
    "    #iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.421"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    72</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    67</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -6400.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 29 Nov 2021</td> <th>  Deviance:          </th> <td>  12220.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:48:26</td>     <th>  Pearson chi2:      </th> <td>1.18e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>6</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -4.2856</td> <td>    0.185</td> <td>  -23.158</td> <td> 0.000</td> <td>   -4.648</td> <td>   -3.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.6455</td> <td>    0.006</td> <td>  106.625</td> <td> 0.000</td> <td>    0.634</td> <td>    0.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.6765</td> <td>    0.006</td> <td>  116.577</td> <td> 0.000</td> <td>    0.665</td> <td>    0.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.9052</td> <td>    0.010</td> <td>  -92.476</td> <td> 0.000</td> <td>   -0.924</td> <td>   -0.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.6286</td> <td>    0.028</td> <td>  -22.377</td> <td> 0.000</td> <td>   -0.684</td> <td>   -0.574</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   72\n",
       "Model:                            GLM   Df Residuals:                       67\n",
       "Model Family:                 Poisson   Df Model:                            4\n",
       "Link Function:                    log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -6400.5\n",
       "Date:                Mon, 29 Nov 2021   Deviance:                       12220.\n",
       "Time:                        19:48:26   Pearson chi2:                 1.18e+04\n",
       "No. Iterations:                     6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -4.2856      0.185    -23.158      0.000      -4.648      -3.923\n",
       "x1             0.6455      0.006    106.625      0.000       0.634       0.657\n",
       "x2             0.6765      0.006    116.577      0.000       0.665       0.688\n",
       "x3            -0.9052      0.010    -92.476      0.000      -0.924      -0.886\n",
       "x4            -0.6286      0.028    -22.377      0.000      -0.684      -0.574\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Aj = sum(Dj* (Dij**opt_sigma))\n",
    "Aij = Aj - Dj* (Dij**opt_sigma)\n",
    "ln_Aij = np.log(Aij)\n",
    "X = sm.add_constant(np.column_stack((ln_Oi, ln_Wj, ln_Dij, ln_Aij)))\n",
    "sm.GLM(flows, X, family=sm.families.Poisson(),).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the method `sa()` to get the Aij array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#spatial accessibility\n",
    "def sa(m, d, sigma_min = -10, sigma_max = 0, step = 0.382, tol = 1e-8):\n",
    "    \n",
    "    def aic_func(sigma):\n",
    "        #calculate different aic value with different sigma values\n",
    "        \n",
    "        #calculate the Aij\n",
    "        Aj = sum(m* (d**sigma))\n",
    "        Aij = Aj - m* (d**sigma)\n",
    "        ln_Aij = np.log(Aij)\n",
    "    \n",
    "        X = np.column_stack((ln_Oi, ln_Wj, ln_Dij, ln_Aij))\n",
    "        mod = OLS(flows, add_constant(X)).fit()\n",
    "        # use ordinary least square\n",
    "        # mod = sm.GLM(flows, X, family=sm.families.Poisson(),).fit()\n",
    "        \n",
    "        return mod.aic\n",
    "    \n",
    "    def find_opt_sigma(sigma_a = sigma_min, sigma_c = sigma_max, step = step, tol = tol):\n",
    "        sigma_b = sigma_min + step * np.abs(sigma_max - sigma_min)\n",
    "        sigma_d = sigma_max - step * np.abs(sigma_max - sigma_min)\n",
    "        \n",
    "        diff = np.inf\n",
    "        opt_sigma = np.inf\n",
    "    \n",
    "        while (diff > tol) :# and (iters <= max_iter)\n",
    "            \n",
    "            aic_b = aic_func(sigma_b)\n",
    "            aic_d = aic_func(sigma_d)\n",
    "            \n",
    "            if aic_b <= aic_d: #discard the old c, b<d<c\n",
    "                opt_sigma = sigma_b\n",
    "                sigma_c = sigma_d\n",
    "                sigma_d = sigma_b\n",
    "                sigma_b = sigma_a + step * np.abs(sigma_c - sigma_a)\n",
    "            \n",
    "            else: # discard the old a, a<b<d\n",
    "                opt_sigma = sigma_d\n",
    "                sigma_a = sigma_b\n",
    "                sigma_b = sigma_d\n",
    "                sigma_d = sigma_c - step * np.abs(sigma_c - sigma_a)\n",
    "            \n",
    "            diff = np.abs(aic_b - aic_d)      \n",
    "            opt_sigma = np.round(opt_sigma, 3) \n",
    "\n",
    "        return opt_sigma\n",
    "    \n",
    "    opt_sigma = find_opt_sigma()\n",
    "    Aj = sum(m * (d ** opt_sigma))\n",
    "    Aij = Aj - m * (d ** opt_sigma)\n",
    "    ln_Aij = np.log(Aij)\n",
    "    \n",
    "    return ln_Aij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.64549418,  0.67648627, -0.90520242, -0.62843556, -4.28490387])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ = np.column_stack((np.log(Oi), np.log(Dj), np.log(Dij), sa(Dj, Dij)))\n",
    "\n",
    "mod_gam = PoissonGAM( l(0) + l(1) + l(2) + l(3),  fit_intercept = True).fit(X_, flows)\n",
    "mod_gam.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Extend Terms Class in pygam package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#step 1: convert ln_dkj and ln_mk as dkj and mk\n",
    "#step 2: find optimal sigma with golden selection\n",
    "#step 3: calculate and return Aij column\n",
    "\n",
    "class SpatialSmoother(LinearTerm): \n",
    "    def __init__(self, feature_m, feature_d, lam=0.6, penalties='auto', verbose=False,\n",
    "                 sigma_min = -10, sigma_max = 0, step = 0.382, tol = 1e-8):\n",
    "        \n",
    "        self._name = 'spatial_smoother'\n",
    "        self._minimal_name = 'ss'\n",
    "        opt_sigma = np.inf\n",
    "        \n",
    "        super(SpatialSmoother, self).__init__(\n",
    "            feature = feature_m, lam = lam, penalties = penalties,verbose = verbose)\n",
    "        self._exclude += ['fit_splines', 'fit_linear', 'dtype', 'constraints']\n",
    "        \n",
    "    @property\n",
    "    def n_coefs(self):\n",
    "        \"\"\"Number of coefficients contributed by the term to the model\n",
    "        \"\"\"\n",
    "        return 1\n",
    "    \n",
    "    def optimal_sigma(self): \n",
    "        \n",
    "        return opt_sigma\n",
    "    \n",
    "    def compile(self, X, verbose=False):\n",
    "        if self.feature >= X.shape[1]:\n",
    "            raise ValueError('term requires feature {}, '\\\n",
    "                             'but X has only {} dimensions'\\\n",
    "                             .format(self.feature, X.shape[1]))\n",
    "\n",
    "        self.edge_knots_ = gen_edge_knots(X[:, self.feature],\n",
    "                                          self.dtype,\n",
    "                                          verbose=verbose)\n",
    "        return self\n",
    "    \n",
    "    def build_columns(self, X, y, verbose=False):\n",
    "        \n",
    "        def aic_func(sigma, m = exp(X[:,self.feature_m]), d = exp(X[:,self.feature_d]) , X = X, y = y):\n",
    "            #calculate the Aij\n",
    "            Aj = sum(m* (d**sigma))\n",
    "            Aij = Aj - m* (d**sigma)\n",
    "            ln_Aij = np.row_stack(log(Aij))\n",
    "        \n",
    "            X_new = np.append(X, ln_Aij, 1)\n",
    "            mod = OLS(flows, add_constant(X_new)).fit()\n",
    "            #mod = sm.GLM(flows, X, family=sm.families.Poisson(),).fit()\n",
    "        \n",
    "            return mod.aic\n",
    "    \n",
    "        def find_opt_sigma(sigma_a = self.sigma_min, sigma_c = self.sigma_max, step = self.step, tol = self.tol):\n",
    "            sigma_b = sigma_min + step * np.abs(sigma_max - sigma_min)\n",
    "            sigma_d = sigma_max - step * np.abs(sigma_max - sigma_min)\n",
    "        \n",
    "            diff = np.inf\n",
    "            #opt_sigma = np.inf            \n",
    "            while (diff > tol) :# and (iters <= max_iter)\n",
    "                aic_b = aic_func(sigma_b)\n",
    "                aic_d = aic_func(sigma_d)\n",
    "                   \n",
    "                if aic_b <= aic_d: #discard the old c, b<d<c\n",
    "                    opt_sigma = sigma_b\n",
    "                    sigma_c = sigma_d\n",
    "                    sigma_d = sigma_b\n",
    "                    sigma_b = sigma_a + step * np.abs(sigma_c - sigma_a)\n",
    "            \n",
    "                else: # discard the old a, a<b<d                    \n",
    "                    opt_sigma = sigma_d\n",
    "                    sigma_a = sigma_b\n",
    "                    sigma_b = sigma_d\n",
    "                    sigma_d = sigma_c - step * np.abs(sigma_c - sigma_a)\n",
    "            \n",
    "                diff = np.abs(aic_b - aic_d)      \n",
    "                opt_sigma = np.round(opt_sigma, 3) \n",
    "\n",
    "            return opt_sigma\n",
    "\n",
    "        Aj = sum(exp(X[:,self.feature_m]) * (exp(X[:,self.feature_d]) ** find_opt_sigma()))\n",
    "        Aij = Aj - exp(X[:,self.feature_m]) * (exp(X[:,self.feature_d]) ** find_opt_sigma())\n",
    "        ln_Aij = log(Aij)\n",
    "        print(ln_Aij.shape)\n",
    "\n",
    "        return LinearTerm(feature=-1, lam=lam, penalties=penalties, verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.70317694,  0.73760879, -1.05938152, -0.85759029])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.column_stack((ln_Oi, ln_Wj, ln_Dij))\n",
    "mod_gam = PoissonGAM(l(0) + l(1) + l(2),  fit_intercept = True).fit(X, flows)\n",
    "mod_gam.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "l??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sa(feature, lam=0.6, penalties='auto', verbose=False):\n",
    "    \"\"\"\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    LinearTerm : for developer details\n",
    "    \"\"\"\n",
    "    return LinearTerm(feature=feature, lam=lam, penalties=penalties, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = SpatialSmoother(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "build_columns() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-328051868ee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: build_columns() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "t.build_columns(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "PoissonGAM??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=LinearTerm(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[10.15584033],\n",
       "        [10.20285113],\n",
       "        [ 8.32288002],\n",
       "        [ 9.06346318],\n",
       "        [ 9.01103541],\n",
       "        [ 8.49739856],\n",
       "        [ 8.28197706],\n",
       "        [ 7.55485852],\n",
       "        [ 8.54597499],\n",
       "        [10.20285113],\n",
       "        [ 8.32288002],\n",
       "        [ 9.06346318],\n",
       "        [ 9.01103541],\n",
       "        [ 8.49739856],\n",
       "        [ 8.28197706],\n",
       "        [ 7.55485852],\n",
       "        [ 8.54597499],\n",
       "        [10.15584033],\n",
       "        [ 8.32288002],\n",
       "        [ 9.06346318],\n",
       "        [ 9.01103541],\n",
       "        [ 8.49739856],\n",
       "        [ 8.28197706],\n",
       "        [ 7.55485852],\n",
       "        [ 8.54597499],\n",
       "        [10.15584033],\n",
       "        [10.20285113],\n",
       "        [ 9.06346318],\n",
       "        [ 9.01103541],\n",
       "        [ 8.49739856],\n",
       "        [ 8.28197706],\n",
       "        [ 7.55485852],\n",
       "        [ 8.54597499],\n",
       "        [10.15584033],\n",
       "        [10.20285113],\n",
       "        [ 8.32288002],\n",
       "        [ 9.01103541],\n",
       "        [ 8.49739856],\n",
       "        [ 8.28197706],\n",
       "        [ 7.55485852],\n",
       "        [ 8.54597499],\n",
       "        [10.15584033],\n",
       "        [10.20285113],\n",
       "        [ 8.32288002],\n",
       "        [ 9.06346318],\n",
       "        [ 8.49739856],\n",
       "        [ 8.28197706],\n",
       "        [ 7.55485852],\n",
       "        [ 8.54597499],\n",
       "        [10.15584033],\n",
       "        [10.20285113],\n",
       "        [ 8.32288002],\n",
       "        [ 9.06346318],\n",
       "        [ 9.01103541],\n",
       "        [ 8.28197706],\n",
       "        [ 7.55485852],\n",
       "        [ 8.54597499],\n",
       "        [10.15584033],\n",
       "        [10.20285113],\n",
       "        [ 8.32288002],\n",
       "        [ 9.06346318],\n",
       "        [ 9.01103541],\n",
       "        [ 8.49739856],\n",
       "        [ 7.55485852],\n",
       "        [ 8.54597499],\n",
       "        [10.15584033],\n",
       "        [10.20285113],\n",
       "        [ 8.32288002],\n",
       "        [ 9.06346318],\n",
       "        [ 9.01103541],\n",
       "        [ 8.49739856],\n",
       "        [ 8.28197706]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.build_columns(X).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearTerm??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spatial accessibility\n",
    "def sa(m, d, sigma_min = -3, sigma_max =0, step = 0.382, tol = 1e-8):\n",
    "    \n",
    "    def aic_func(sigma):\n",
    "        #calculate different aic value with different sigma values\n",
    "        \n",
    "        #calculate the Aij\n",
    "        Aj = sum(m* (d**sigma))\n",
    "        Aij = Aj - m* (d**sigma)\n",
    "        ln_Aij = np.log(Aij)\n",
    "    \n",
    "        X = np.column_stack((ln_Oi, ln_Wj, ln_Dij, ln_Aij))\n",
    "        mod = OLS(flows, add_constant(X)).fit()\n",
    "        # use ordinary least square\n",
    "        # mod = sm.GLM(flows, X, family=sm.families.Poisson(),).fit()\n",
    "        print(sigma,mod.aic)\n",
    "        return mod.aic\n",
    "    \n",
    "    def find_opt_sigma(sigma_a = sigma_min, sigma_c = sigma_max, step = step, tol = tol):\n",
    "        sigma_b = sigma_min + step * np.abs(sigma_max - sigma_min)\n",
    "        sigma_d = sigma_max - step * np.abs(sigma_max - sigma_min)\n",
    "        \n",
    "        diff = np.inf\n",
    "        opt_sigma = np.inf\n",
    "    \n",
    "        while (diff > tol) :# and (iters <= max_iter)\n",
    "            \n",
    "            aic_b = aic_func(sigma_b)\n",
    "            aic_d = aic_func(sigma_d)\n",
    "            \n",
    "            if aic_b <= aic_d: #discard the old c, b<d<c\n",
    "                opt_sigma = sigma_b\n",
    "                sigma_c = sigma_d\n",
    "                sigma_d = sigma_b\n",
    "                sigma_b = sigma_a + step * np.abs(sigma_c - sigma_a)\n",
    "            \n",
    "            else: # discard the old a, a<b<d\n",
    "                opt_sigma = sigma_d\n",
    "                sigma_a = sigma_b\n",
    "                sigma_b = sigma_d\n",
    "                sigma_d = sigma_c - step * np.abs(sigma_c - sigma_a)\n",
    "            \n",
    "            diff = np.abs(aic_b - aic_d)      \n",
    "            opt_sigma = np.round(opt_sigma, 3) \n",
    "        \n",
    "        return opt_sigma\n",
    "    \n",
    "    opt_sigma = find_opt_sigma()\n",
    "    print(opt_sigma)\n",
    "    Aj = sum(m * (d ** opt_sigma))\n",
    "    Aij = Aj - m * (d ** opt_sigma)\n",
    "    ln_Aij = np.log(Aij)\n",
    "    \n",
    "    return Aij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "class LinearTerm(Term):\n",
    "    def __init__(self, feature, lam=0.6, penalties='auto', verbose=False):\n",
    "        \"\"\"creates an instance of a LinearTerm\n",
    "        Parameters\n",
    "        ----------\n",
    "        feature : int\n",
    "            Index of the feature to use for the feature function.\n",
    "        lam :  float or iterable of floats\n",
    "            Strength of smoothing penalty. Must be a positive float.\n",
    "            Larger values enforce stronger smoothing.\n",
    "            If single value is passed, it will be repeated for every penalty.\n",
    "            If iterable is passed, the length of `lam` must be equal to the\n",
    "            length of `penalties`\n",
    "        penalties : {'auto', 'derivative', 'l2', None} or callable or iterable\n",
    "            Type of smoothing penalty to apply to the term.\n",
    "            If an iterable is used, multiple penalties are applied to the term.\n",
    "            The length of the iterable must match the length of `lam`.\n",
    "            If 'auto', then 2nd derivative smoothing for 'numerical' dtypes,\n",
    "            and L2/ridge smoothing for 'categorical' dtypes.\n",
    "            Custom penalties can be passed as a callable.\n",
    "        Attributes\n",
    "        ----------\n",
    "        n_coefs : int\n",
    "            Number of coefficients contributed by the term to the model\n",
    "        istensor : bool\n",
    "            whether the term is a tensor product of sub-terms\n",
    "        isintercept : bool\n",
    "            whether the term is an intercept\n",
    "        hasconstraint : bool\n",
    "            whether the term has any constraints\n",
    "        info : dict\n",
    "            contains dict with the sufficient information to duplicate the term\n",
    "        \"\"\"\n",
    "        self._name = 'linear_term'\n",
    "        self._minimal_name = 'l'\n",
    "        super(LinearTerm, self).__init__(feature=feature, lam=lam,\n",
    "                                         penalties=penalties,\n",
    "                                         constraints=None, dtype='numerical',\n",
    "                                         fit_linear=True, fit_splines=False,\n",
    "                                         verbose=verbose)\n",
    "        self._exclude += ['fit_splines', 'fit_linear', 'dtype', 'constraints']\n",
    "\n",
    "    @property\n",
    "    def n_coefs(self):\n",
    "        \"\"\"Number of coefficients contributed by the term to the model\n",
    "        \"\"\"\n",
    "        return 1\n",
    "\n",
    "    def compile(self, X, verbose=False):\n",
    "        \"\"\"method to validate and prepare data-dependent parameters\n",
    "        Parameters\n",
    "        ---------\n",
    "        X : array-like\n",
    "            Input dataset\n",
    "        verbose : bool\n",
    "            whether to show warnings\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        if self.feature >= X.shape[1]:\n",
    "            raise ValueError('term requires feature {}, '\\\n",
    "                             'but X has only {} dimensions'\\\n",
    "                             .format(self.feature, X.shape[1]))\n",
    "\n",
    "        self.edge_knots_ = gen_edge_knots(X[:, self.feature],\n",
    "                                          self.dtype,\n",
    "                                          verbose=verbose)\n",
    "        return self\n",
    "\n",
    "    def build_columns(self, X, verbose=False):\n",
    "        \"\"\"construct the model matrix columns for the term\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like\n",
    "            Input dataset with n rows\n",
    "        verbose : bool\n",
    "            whether to show warnings\n",
    "        Returns\n",
    "        -------\n",
    "        scipy sparse array with n rows\n",
    "        \"\"\"\n",
    "        Aij = sa(X[:, 1], X[:, 2])\n",
    "        return sp.sparse.csc_matrix(Aij[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.854 1221.3788754973707\n",
      "-1.146 1229.4972468512647\n",
      "-2.291772 1217.1365910498578\n",
      "-1.854 1221.3788754973707\n",
      "-2.562228 1214.6730456450198\n",
      "-2.291772 1217.1365910498578\n",
      "-2.729456904 1213.190792462041\n",
      "-2.562228 1214.6730456450198\n",
      "-2.832771096 1212.287510702623\n",
      "-2.729456904 1213.190792462041\n",
      "-2.896652537328 1211.7331405319346\n",
      "-2.832771096 1212.287510702623\n",
      "-2.9361185586720002 1211.3921084781405\n",
      "-2.896652537328 1211.7331405319346\n",
      "-2.960521269259296 1211.1817708074298\n",
      "-2.9361185586720002 1211.3921084781405\n",
      "-2.975597289412704 1211.0520202364303\n",
      "-2.960521269259296 1211.1817708074298\n",
      "-2.984919124857051 1210.9718661972868\n",
      "-2.975597289412704 1211.0520202364303\n",
      "-2.990678164555653 1210.922374729928\n",
      "-2.984919124857051 1210.9718661972868\n",
      "-2.9942391056953936 1210.8917836058736\n",
      "-2.990678164555653 1210.922374729928\n",
      "-2.9964390588602594 1210.8728883849933\n",
      "-2.9942391056953936 1210.8917836058736\n",
      "-2.9977993383756405 1210.8612065808281\n",
      "-2.9964390588602594 1210.8728883849933\n",
      "-2.998639720484619 1210.8539901322258\n",
      "-2.9977993383756405 1210.8612065808281\n",
      "-2.9991593472594946 1210.849528265307\n",
      "-2.998639720484619 1210.8539901322258\n",
      "-2.9994803732251243 1210.8467718040708\n",
      "-2.9991593472594946 1210.849528265307\n",
      "-2.9996788706531268 1210.8450674557546\n",
      "-2.9994803732251243 1210.8467718040708\n",
      "-2.9998015025719975 1210.844014519947\n",
      "-2.9996788706531268 1210.8450674557546\n",
      "-2.9998773285894944 1210.8433634712644\n",
      "-2.9998015025719975 1210.844014519947\n",
      "-2.999924173982503 1210.8429612545106\n",
      "-2.9998773285894944 1210.8433634712644\n",
      "-2.9999531395211867 1210.8427125557178\n",
      "-2.999924173982503 1210.8429612545106\n",
      "-2.999971034461316 1210.8425589096084\n",
      "-2.9999531395211867 1210.8427125557178\n",
      "-2.9999820992970934 1210.8424639069333\n",
      "-2.999971034461316 1210.8425589096084\n",
      "-2.9999889351642226 1210.8424052142213\n",
      "-2.9999820992970934 1210.8424639069333\n",
      "-2.9999931619314895 1210.8423689232368\n",
      "-2.9999889351642226 1210.8424052142213\n",
      "-2.999995773232733 1210.8423465026337\n",
      "-2.9999931619314895 1210.8423689232368\n",
      "-2.999997387857829 1210.8423326394861\n",
      "-2.999995773232733 1210.8423465026337\n",
      "-2.999998385374904 1210.8423240748175\n",
      "-2.999997387857829 1210.8423326394861\n",
      "-2.9999990021616907 1210.842318779097\n",
      "-2.999998385374904 1210.8423240748175\n",
      "-2.9999993832132135 1210.842315507391\n",
      "-2.9999990021616907 1210.842318779097\n",
      "-2.999999618825766 1210.8423134844281\n",
      "-2.9999993832132135 1210.842315507391\n",
      "-2.9999997643874474 1210.8423122346367\n",
      "-2.999999618825766 1210.8423134844281\n",
      "-2.999999854391443 1210.842311461862\n",
      "-2.9999997643874474 1210.8423122346367\n",
      "-2.999999909996005 1210.8423109844437\n",
      "-2.999999854391443 1210.842311461862\n",
      "-2.999999944377531 1210.842310689243\n",
      "-2.999999909996005 1210.8423109844437\n",
      "-2.999999965618474 1210.8423105068666\n",
      "-2.999999944377531 1210.842310689243\n",
      "-2.999999978752217 1210.8423103941032\n",
      "-2.999999965618474 1210.8423105068666\n",
      "-2.999999986866257 1210.8423103244368\n",
      "-2.999999978752217 1210.8423103941032\n",
      "-2.999999991883347 1210.842310281358\n",
      "-2.999999986866257 1210.8423103244368\n",
      "-2.99999999498291 1210.8423102547454\n",
      "-2.999999991883347 1210.842310281358\n",
      "-2.9999999968994384 1210.84231023829\n",
      "-2.99999999498291 1210.8423102547454\n",
      "-2.9999999980834717 1210.8423102281254\n",
      "-2.9999999968994384 1210.84231023829\n",
      "-2.9999999988155857 1210.8423102218405\n",
      "-2.9999999980834717 1210.8423102281254\n",
      "-3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[4.67650878],\n",
       "        [4.66141819],\n",
       "        [4.72558282],\n",
       "        [4.70066526],\n",
       "        [4.72027396],\n",
       "        [4.72769703],\n",
       "        [4.7395617 ],\n",
       "        [4.7471946 ],\n",
       "        [4.69267883],\n",
       "        [4.59608653],\n",
       "        [4.72506641],\n",
       "        [4.69988222],\n",
       "        [4.70407289],\n",
       "        [4.72158484],\n",
       "        [4.73691924],\n",
       "        [4.74551073],\n",
       "        [4.68043437],\n",
       "        [4.5969271 ],\n",
       "        [4.72906663],\n",
       "        [4.70883093],\n",
       "        [4.71545581],\n",
       "        [4.72737726],\n",
       "        [4.73939833],\n",
       "        [4.74699268],\n",
       "        [4.7241639 ],\n",
       "        [4.71329477],\n",
       "        [4.71789664],\n",
       "        [4.68077382],\n",
       "        [4.70739015],\n",
       "        [4.68719664],\n",
       "        [4.72200455],\n",
       "        [4.73823263],\n",
       "        [4.70511033],\n",
       "        [4.69040466],\n",
       "        [4.70007046],\n",
       "        [4.68876055],\n",
       "        [4.69828824],\n",
       "        [4.70204435],\n",
       "        [4.73053868],\n",
       "        [4.74229748],\n",
       "        [4.72327992],\n",
       "        [4.69461508],\n",
       "        [4.70711514],\n",
       "        [4.71282202],\n",
       "        [4.69782145],\n",
       "        [4.6790161 ],\n",
       "        [4.72412046],\n",
       "        [4.73881778],\n",
       "        [4.7274065 ],\n",
       "        [4.71047323],\n",
       "        [4.71711324],\n",
       "        [4.68907218],\n",
       "        [4.69694999],\n",
       "        [4.67300159],\n",
       "        [4.71134956],\n",
       "        [4.73445037],\n",
       "        [4.73831993],\n",
       "        [4.72750728],\n",
       "        [4.73032523],\n",
       "        [4.72172545],\n",
       "        [4.72601139],\n",
       "        [4.71933191],\n",
       "        [4.70960246],\n",
       "        [4.70758899],\n",
       "        [4.74308536],\n",
       "        [4.73414714],\n",
       "        [4.73594313],\n",
       "        [4.73413729],\n",
       "        [4.7350648 ],\n",
       "        [4.73116575],\n",
       "        [4.72895257],\n",
       "        [4.70076245]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = LinearTerm(1)\n",
    "t.build_columns(X).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.gam import AdditiveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = AdditiveModel(X).fit(flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -407.18380385,   923.11933108,   150.18464731],\n",
       "       [ -407.18380385,   911.8765729 ,  1714.08265829],\n",
       "       [ -407.18380385,  -521.66105409,  -501.06814841],\n",
       "       [ -407.18380385,   162.85051464,  -731.50530955],\n",
       "       [ -407.18380385,   103.5912678 ,  -543.8117024 ],\n",
       "       [ -407.18380385,  -408.72060003,  -344.65574272],\n",
       "       [ -407.18380385,  -541.26779348,  -517.91826136],\n",
       "       [ -407.18380385,  -259.88645747, -1832.8422128 ],\n",
       "       [  675.26801703,  -369.90178135,   150.18464731],\n",
       "       [  675.26801703,   911.8765729 , 13290.01044458],\n",
       "       [  675.26801703,  -521.66105409,  -526.81797089],\n",
       "       [  675.26801703,   162.85051464,  -702.03535653],\n",
       "       [  675.26801703,   103.5912678 ,  -815.57326982],\n",
       "       [  675.26801703,  -408.72060003,  -636.2717442 ],\n",
       "       [  675.26801703,  -541.26779348,  -256.25703522],\n",
       "       [  675.26801703,  -259.88645747, -1132.62749696],\n",
       "       [  997.22845251,  -369.90178135,  1714.08265829],\n",
       "       [  997.22845251,   923.11933108, 13290.01044458],\n",
       "       [  997.22845251,  -521.66105409,  -329.56509124],\n",
       "       [  997.22845251,   162.85051464,  -856.15939513],\n",
       "       [  997.22845251,   103.5912678 ,  -735.69776832],\n",
       "       [  997.22845251,  -408.72060003,  -359.47935983],\n",
       "       [  997.22845251,  -541.26779348,  -494.10763221],\n",
       "       [  997.22845251,  -259.88645747, -1733.34871506],\n",
       "       [ -358.22732462,  -369.90178135,  -501.06814841],\n",
       "       [ -358.22732462,   923.11933108,  -526.81797089],\n",
       "       [ -358.22732462,   911.8765729 ,  -329.56509124],\n",
       "       [ -358.22732462,   162.85051464,   882.78734957],\n",
       "       [ -358.22732462,   103.5912678 ,  -857.03934053],\n",
       "       [ -358.22732462,  -408.72060003,   841.67479994],\n",
       "       [ -358.22732462,  -541.26779348,  -680.2455615 ],\n",
       "       [ -358.22732462,  -259.88645747,  -189.25926079],\n",
       "       [  -57.64013726,  -369.90178135,  -731.50530955],\n",
       "       [  -57.64013726,   923.11933108,  -702.03535653],\n",
       "       [  -57.64013726,   911.8765729 ,  -856.15939513],\n",
       "       [  -57.64013726,  -521.66105409,   882.78734957],\n",
       "       [  -57.64013726,   103.5912678 ,  -610.06139373],\n",
       "       [  -57.64013726,  -408.72060003,  -564.95742082],\n",
       "       [  -57.64013726,  -541.26779348,  -276.4500204 ],\n",
       "       [  -57.64013726,  -259.88645747,  -417.81228218],\n",
       "       [  116.43680717,  -369.90178135,  -543.8117024 ],\n",
       "       [  116.43680717,   923.11933108,  -815.57326982],\n",
       "       [  116.43680717,   911.8765729 ,  -735.69776832],\n",
       "       [  116.43680717,  -521.66105409,  -857.03934053],\n",
       "       [  116.43680717,   162.85051464,  -610.06139373],\n",
       "       [  116.43680717,  -408.72060003,  2021.17143625],\n",
       "       [  116.43680717,  -541.26779348,  -585.81416023],\n",
       "       [  116.43680717,  -259.88645747,  -193.34357776],\n",
       "       [ -289.63600079,  -369.90178135,  -344.65574272],\n",
       "       [ -289.63600079,   923.11933108,  -636.2717442 ],\n",
       "       [ -289.63600079,   911.8765729 ,  -359.47935983],\n",
       "       [ -289.63600079,  -521.66105409,   841.67479994],\n",
       "       [ -289.63600079,   162.85051464,  -564.95742082],\n",
       "       [ -289.63600079,   103.5912678 ,  2021.17143625],\n",
       "       [ -289.63600079,  -541.26779348,  -839.37926604],\n",
       "       [ -289.63600079,  -259.88645747,  -289.94974662],\n",
       "       [ -392.45512641,  -369.90178135,  -517.91826136],\n",
       "       [ -392.45512641,   923.11933108,  -256.25703522],\n",
       "       [ -392.45512641,   911.8765729 ,  -494.10763221],\n",
       "       [ -392.45512641,  -521.66105409,  -680.2455615 ],\n",
       "       [ -392.45512641,   162.85051464,  -276.4500204 ],\n",
       "       [ -392.45512641,   103.5912678 ,  -585.81416023],\n",
       "       [ -392.45512641,  -408.72060003,  -839.37926604],\n",
       "       [ -392.45512641,  -259.88645747,  -345.8570927 ],\n",
       "       [ -283.79088379,  -369.90178135, -1832.8422128 ],\n",
       "       [ -283.79088379,   923.11933108, -1132.62749696],\n",
       "       [ -283.79088379,   911.8765729 , -1733.34871506],\n",
       "       [ -283.79088379,  -521.66105409,  -189.25926079],\n",
       "       [ -283.79088379,   162.85051464,  -417.81228218],\n",
       "       [ -283.79088379,   103.5912678 ,  -193.34357776],\n",
       "       [ -283.79088379,  -408.72060003,  -289.94974662],\n",
       "       [ -283.79088379,  -541.26779348,  -345.8570927 ]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.smoothed(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lagwr",
   "language": "python",
   "name": "lagwr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
