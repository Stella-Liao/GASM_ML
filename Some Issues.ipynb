{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "rising-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from spglm.iwls import iwls, _compute_betas_gwr\n",
    "from spglm.family import *\n",
    "from mgwr.search import golden_section\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import geopandas as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import libpysal.weights as sw\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-configuration",
   "metadata": {},
   "source": [
    "## Some Issues about calculating Aij"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-liability",
   "metadata": {},
   "source": [
    "#### 1. `Dja` and `sw.distance.DistanceBand.from_dataframe()` are not corresponding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-berry",
   "metadata": {},
   "source": [
    "That is how we calculate accessibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-bachelor",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = sw.distance.DistanceBand.from_dataframe(austria_shp,  threshold=99999, binary=False, alpha=sigma)\n",
    "W = W.full()[0]\n",
    "mask = W!=0\n",
    "Aij = (W * Dja[0:9])\n",
    "Aij = Aij[mask].reshape((9,8))\n",
    "Aij = np.tile(np.sum(Aij, axis=1), 9).reshape((9,9))\n",
    "Aij = Aij[mask].reshape((-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-membrane",
   "metadata": {},
   "source": [
    "`Dja` stroes the qualities of destinations, whose rows have the order like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "known-democrat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    AT12\n",
       "2    AT13\n",
       "3    AT21\n",
       "4    AT22\n",
       "5    AT31\n",
       "6    AT32\n",
       "7    AT33\n",
       "8    AT34\n",
       "9    AT11\n",
       "Name: Destination, dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austria['Destination'][0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-stock",
   "metadata": {},
   "source": [
    "And when using `sw.distance.DistanceBand.from_dataframe()`, it used `austria_shp`, whose rows have the order like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "great-thomson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    AT33\n",
       "1    AT34\n",
       "2    AT11\n",
       "3    AT13\n",
       "4    AT31\n",
       "5    AT21\n",
       "6    AT32\n",
       "7    AT12\n",
       "8    AT22\n",
       "Name: NUTS_ID, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austria_shp['NUTS_ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-explanation",
   "metadata": {},
   "source": [
    "So I was wondering in this the command `Aij = (W * Dja[0:9])`, whether we should change either the order of the rows of `austria_shp` nor of `Dja`. So I created `SpatialSmooth2()`, in this method, I re-index the rows of `j_df` which stores the quality and the name of all destinations, followed by the order of the rows of `austria_shp`. \n",
    "\n",
    "But when validating the results with `SpatialSmooth2()` and `ComepteDestiantion2()`, the betas of `iwls()` and of `CompeteDestination2()` are not same and the predicted sigma value is not the same as the sigma we set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "swedish-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpatialSmooth2(m, X_df, pid, geomap, sigma):\n",
    "    \n",
    "    Aij = np.zeros_like(X_df.iloc[:,m]).reshape((-1,1))\n",
    "    X = X_df.copy()\n",
    "        \n",
    "    #obtain the quality of all destinations, mk\n",
    "    j_df = X.drop_duplicates(subset = ['Destination'])\n",
    "        \n",
    "    #rearrange the order of rows which will be followed by the order of the rows of geomap\n",
    "    j_df = j_df.set_index(j_df['Destination'])#.sort_index()\n",
    "    j_df = j_df.reindex(geomap.iloc[:,pid])\n",
    "    mk = j_df.iloc[:,m].values.reshape((-1,1))\n",
    "        \n",
    "    #obtain all destinations\n",
    "    all_places = geomap.iloc[:,pid].values.reshape((-1,1)) #j_df['Destination'].values.reshape((-1,1)) \n",
    "    num_j = len(all_places)\n",
    "        \n",
    "    #create the flow codes\n",
    "    temp_codes = [['DELETE']]\n",
    "    for place in all_places:\n",
    "        temp_places = np.tile(place, (num_j-1,1))\n",
    "        other_places = all_places[all_places != place].reshape((-1,1))\n",
    "        r = other_places + temp_places \n",
    "        temp_codes = np.vstack((temp_codes,r))\n",
    "                \n",
    "    temp_codes = temp_codes[temp_codes != 'DELETE'].reshape((-1,1))\n",
    "\n",
    "    #calculate the accessibility\n",
    "    W = sw.distance.DistanceBand.from_dataframe(geomap, threshold=99999, binary=False, alpha=sigma)\n",
    "    W = W.full()[0]\n",
    "    mask = W!=0\n",
    "    temp_Aij = (W * mk)\n",
    "    temp_Aij = temp_Aij[mask].reshape((num_j,num_j-1))\n",
    "    Aijs = np.zeros(num_j).reshape((-1,1))\n",
    "\n",
    "    for i in range(num_j-1):\n",
    "        temp_aij = np.delete(temp_Aij, i, axis=1)\n",
    "    \n",
    "        temp_aijs = np.sum(temp_aij, axis = 1).reshape((-1,1))\n",
    "        Aijs = np.hstack((Aijs, temp_aijs)) \n",
    "\n",
    "    Aijs = np.delete(Aijs, 0, axis =1).reshape((-1,1))\n",
    "\n",
    "    temp_Aij = pd.DataFrame(np.hstack((temp_codes, Aijs)), columns = ['Code', 'Aij'])\n",
    "        \n",
    "    X_Aij_df = pd.merge(X, temp_Aij, how = 'left', on =  ['Code'])\n",
    "\n",
    "    Aij = pd.to_numeric(X_Aij_df['Aij'].values).reshape((-1,1))\n",
    "\n",
    "\n",
    "    return Aij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "numerical-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompeteDestination2(y, v1, v2, v3, X_df, pid, geomap, is_Spatial=True, verbose=False):\n",
    "    \n",
    "    # build X\n",
    "    def build_X(v1, v2, v3, X_df, pid, geomap, is_Spatial):\n",
    "        \n",
    "        Oi = X_df.iloc[:,v1]\n",
    "        Wj = X_df.iloc[:,v2]\n",
    "        Dij = X_df.iloc[:,v3]\n",
    "        X = np.column_stack((Oi, Wj, Dij))\n",
    "        \n",
    "        if is_Spatial == True:\n",
    "            #initialize the accissibility term with sigma set as -1\n",
    "            init_Aij = SpatialSmooth2(v2, X_df, pid, geomap, -1)\n",
    "            X = np.hstack((X,init_Aij)) \n",
    "        return X\n",
    "    \n",
    "    X = build_X(v1, v2, v3, X_df, pid, geomap, is_Spatial)\n",
    "\n",
    "    s_0 = np.log(np.mean(y))\n",
    "    eta = s_0.reshape((-1, 1))\n",
    "    s_old = np.zeros_like(X)\n",
    "    crit = 9999\n",
    "    sigma = np.inf\n",
    "    \n",
    "    # backfitting - inner loop\n",
    "    def backfit2(y, X, w, v2, X_df, pid, geomap, is_Spatial, verbose):\n",
    "        n,k = X.shape\n",
    "        betas = _compute_betas_gwr(y, np.log(X), w.reshape((-1, 1)))[0]\n",
    "        #print(betas)\n",
    "        XB = np.multiply(betas.T, np.log(X))\n",
    "        yhat = np.dot(np.log(X), betas)\n",
    "        err = y.reshape((-1, 1)) - yhat\n",
    "        iters = 0\n",
    "        scores = []\n",
    "        delta = 1e6\n",
    "        tol = 1e-8\n",
    "        max_iter = 50\n",
    "        sig = np.inf\n",
    "        \n",
    "        if is_Spatial == True:\n",
    "            for iters in range(1, max_iter + 1):\n",
    "                new_XB = np.zeros_like(X)\n",
    "                params = np.zeros_like(betas)\n",
    "\n",
    "                for j in range(k):\n",
    "                    temp_y = XB[:, j].reshape((-1, 1))\n",
    "                    temp_y = temp_y + err.reshape((-1, 1))\n",
    "                    temp_X = np.log(X[:, j]).reshape((-1, 1))\n",
    "\n",
    "                    if j == k-1:\n",
    "                        score = lambda x: sm.OLS(temp_y, np.log(SpatialSmooth2(v2, X_df, pid, geomap, x))).fit().aic\n",
    "                        sig  = golden_section(-6, 6, 0.38197, score, 1e-2, 50)[0]\n",
    "                        Aij = SpatialSmooth2(v2, X_df, pid, geomap, sig)\n",
    "                        X[:, j] = Aij.flatten()\n",
    "                        temp_X = np.log(Aij).reshape((-1, 1))\n",
    "\n",
    "                    beta = _compute_betas_gwr(temp_y, temp_X, w.reshape((-1, 1)))[0]\n",
    "                    #print(beta)\n",
    "                    yhat = np.dot(temp_X, beta)\n",
    "                    new_XB[:, j] = yhat.flatten()\n",
    "                    err = (temp_y - yhat).reshape((-1, 1))\n",
    "                    params[j, :] = beta[0][0]\n",
    "    \n",
    "                num = np.sum((XB-new_XB)**2)\n",
    "                den = 1 + np.sum(np.sum(XB, axis=1)**2)\n",
    "                score = (num / den)\n",
    "                XB = new_XB\n",
    "        \n",
    "                scores.append(deepcopy(score))\n",
    "                delta = score\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"Current iteration:\", iters, \",SOC:\", np.round(score, 8))\n",
    "                if delta < tol:\n",
    "                    break\n",
    "                    \n",
    "        elif is_Spatial == False:\n",
    "            for iters in range(1, max_iter + 1):\n",
    "                new_XB = np.zeros_like(X)\n",
    "                params = np.zeros_like(betas)\n",
    "\n",
    "                for j in range(k):\n",
    "                    temp_y = XB[:, j].reshape((-1, 1))\n",
    "                    temp_y = temp_y + err.reshape((-1, 1))\n",
    "                    temp_X = np.log(X[:, j]).reshape((-1, 1))\n",
    "                    beta = _compute_betas_gwr(temp_y, temp_X, w.reshape((-1, 1)))[0]\n",
    "                    #print(beta)\n",
    "                    yhat = np.dot(temp_X, beta)\n",
    "                    new_XB[:, j] = yhat.flatten()\n",
    "                    err = (temp_y - yhat).reshape((-1, 1))\n",
    "                    params[j, :] = beta[0][0]\n",
    "                    \n",
    "                num = np.sum((XB-new_XB)**2)\n",
    "                den = 1 + np.sum(np.sum(XB, axis=1)**2)\n",
    "                score = (num / den)\n",
    "                XB = new_XB\n",
    "        \n",
    "                scores.append(deepcopy(score))\n",
    "                delta = score\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"Current iteration:\", iters, \",SOC:\", np.round(score, 8))\n",
    "                if delta < tol:\n",
    "                    break\n",
    "\n",
    "        return params, X, sig\n",
    "    \n",
    "    #local scoring - outer loop \n",
    "    while crit > 1e-8:\n",
    "        mu = np.exp(eta).reshape((-1, 1))\n",
    "        w = mu.reshape((-1,1))\n",
    "        z = eta + ((y.reshape((-1, 1)) - mu) / mu)\n",
    "        betas, X, sigma = backfit2(z, X, w, v2, X_df, pid, geomap,is_Spatial, verbose)\n",
    "        s_new = np.multiply(betas.T, np.log(X))\n",
    "        inner = np.sum((s_old - s_new)**2, axis=1)\n",
    "        num = np.sum(w*inner)\n",
    "        den = np.sum(w*np.sum((1 + s_old)**2, axis=1).reshape((-1, 1)))\n",
    "        crit = num / den\n",
    "        eta = np.sum(s_new, axis=1).reshape((-1, 1))\n",
    "        s_old = s_new\n",
    "        \n",
    "    return betas, eta, sigma\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "surprising-child",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Aij2 = SpatialSmooth2(5, X_df, 1, austria_shp, -1.35)\n",
    "X2 = np.column_stack((Oi, Wj, Dij, Aij2))\n",
    "w = np.ones(72).reshape((-1,1))\n",
    "betas2 = iwls(flows.reshape((-1,1)), np.log(X2), family=Poisson(), offset=w.reshape((-1, 1)), y_fix=None, wi=w.reshape((-1, 1)))[0]\n",
    "f2 = np.exp(np.dot(np.log(X2), betas2) + np.random.normal(0, .0001, (72,1))).reshape((-1,1))\n",
    "start2 = time.time()\n",
    "betas_cd2, eta_cd2, sigma_cd2 = CompeteDestination2(f2, 4, 5, 6, X_df, 1, austria_shp, is_Spatial=True, verbose=False)\n",
    "end2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caroline-latex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas_iwls2:\n",
      "[[ 0.62239105]\n",
      " [ 1.23615628]\n",
      " [-1.06479231]\n",
      " [-0.45072998]]\n",
      "betas_cd2:\n",
      "[[ 0.63758331]\n",
      " [ 1.38446578]\n",
      " [-1.04594236]\n",
      " [-0.59791932]]\n",
      "sigma_cd2:\n",
      "-1.05\n",
      "Runtime for ComepeteDestination2():\n",
      "26.739388465881348\n"
     ]
    }
   ],
   "source": [
    "print('betas_iwls2:', betas2, 'betas_cd2:', betas_cd2,'sigma_cd2:', sigma_cd2, 'Runtime for ComepeteDestination2():', end2 - start2, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-delhi",
   "metadata": {},
   "source": [
    "#### 2. Which could be considered as an alternative destination for a flow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-indonesian",
   "metadata": {},
   "source": [
    "So far, when calculating the accessibilty for each flow in the case of Austria, we assume the possible destinations will be all the places except the origin as for a flow. For example, for the flow 'AT11AT12', the target destination is 'AT12', and other possible destinations are 'AT13', 'AT21', 'AT22', 'AT31', 'AT32', 'AT33', 'AT34'.\n",
    "\n",
    "However, one situation would happen, which is that not every origin will also be a destination. Continuing to take the flow 'AT11AT12' as an example, in fact, the alternative destinations for this flow are those who have the interactions with the origin, 'AT11'. And it is possible that except the origin 'AT11' and the target destination 'AT12', only 'AT13','AT21' and 'AT22' have interactions with 'AT11'.(Of course, in the case of Austria, every place has the interaction with each other, however, this situation is possible). \n",
    "\n",
    "So I wrote `SpatialSmooth3()` to consider the situation above and I hope the users could tell whether each origin will also be a destination before modelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "thirty-hypothetical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpatialSmooth3(m, X_df, pid, geomap, sigma, is_Each = False):\n",
    "    \n",
    "    '''\n",
    "    is_Each: whether every destination will also be an origin, by default it is false\n",
    "\n",
    "    '''\n",
    "    Aij = np.zeros_like(X_df.iloc[:,m]).reshape((-1,1))\n",
    "    \n",
    "    if is_Each == False:\n",
    "        X = X_df.copy()\n",
    "        temp_df = pd.DataFrame()\n",
    "        for temp_or in X['Origin']: \n",
    "    \n",
    "            #find all flows whose origin is temp_or\n",
    "            j_df = X[X['Origin'] == temp_or]        \n",
    "            temp_j = j_df['Destination'].values\n",
    "            #split the geomap and only remain the geometries of the destinations of temp_j \n",
    "            temp_shp = geomap.loc[geomap.iloc[:,pid].isin(temp_j)] \n",
    "            \n",
    "            j_df = j_df.set_index(j_df['Destination'])\n",
    "            j_df = j_df.reindex(temp_shp.iloc[:,pid])\n",
    "            \n",
    "            mk = j_df.iloc[:,m].values.reshape((-1,1)) \n",
    "            num_j = len(temp_j)\n",
    "            \n",
    "            #obtain all destinations\n",
    "            all_places = j_df['Destination']#temp_shp.iloc[:,pid].values.reshape((-1,1)) \n",
    "            \n",
    "            #create the flow codes\n",
    "            temp_codes = [['DELETE']]\n",
    "        \n",
    "            for place in all_places:\n",
    "                r = temp_or + place\n",
    "                temp_codes = np.vstack((temp_codes,r))\n",
    "                \n",
    "            temp_codes = temp_codes[temp_codes != 'DELETE'].reshape((-1,1))\n",
    "            \n",
    "            #calculate the accessibility\n",
    "            W = sw.distance.DistanceBand.from_dataframe(temp_shp, threshold=99999, binary=False, alpha=sigma)\n",
    "            W = W.full()[0]\n",
    "            mask = W!=0 \n",
    "            temp_Aij = (W * mk)\n",
    "            temp_Aij = temp_Aij[mask].reshape((num_j,num_j-1))\n",
    "            temp_Aij = np.sum(temp_Aij, axis=1).reshape((-1,1))\n",
    "            temp_Aij = pd.DataFrame(np.hstack((temp_codes, temp_Aij)), columns = ['Code', 'Aij'])\n",
    "            temp_df = temp_df.append(temp_Aij)\n",
    "            \n",
    "        temp_df = temp_df.drop_duplicates(subset = ['Code'])\n",
    "        temp_df = temp_df.set_index(temp_df['Code'])\n",
    "        temp_df = temp_df.reindex(X['Code'])\n",
    "            \n",
    "        #X_Aij_df = pd.merge(X, temp_df, how = 'left', on =  ['Code'])\n",
    "        Aij = pd.to_numeric(temp_df['Aij'].values).reshape((-1,1))   \n",
    "\n",
    "    elif is_Each == True:\n",
    "        X = X_df.copy()\n",
    "        \n",
    "        #obtain the quality of all destinations, mk\n",
    "        j_df = X.drop_duplicates(subset = ['Destination'])\n",
    "        j_df = j_df.set_index(j_df['Destination']).sort_index()\n",
    "        mk = j_df.iloc[:,m].values.reshape((-1,1))\n",
    "        \n",
    "        #obtain all destinations\n",
    "        all_places = geomap.iloc[:,pid].values.reshape((-1,1)) \n",
    "        num_j = len(all_places)\n",
    "        \n",
    "        #create the flow codes\n",
    "        temp_codes = [['DELETE']]\n",
    "        \n",
    "        for place in all_places:\n",
    "            temp_places = np.tile(place, (num_j-1,1))\n",
    "            other_places = all_places[all_places != place].reshape((-1,1))\n",
    "            r = temp_places + other_places\n",
    "            temp_codes = np.vstack((temp_codes,r))\n",
    "                \n",
    "        temp_codes = temp_codes[temp_codes != 'DELETE'].reshape((-1,1))\n",
    "     \n",
    "        #calculate the accessibility\n",
    "        W = sw.distance.DistanceBand.from_dataframe(geomap, threshold=99999, binary=False, alpha=sigma)\n",
    "        W = W.full()[0]\n",
    "        mask = W!=0\n",
    "        temp_Aij = (W * mk)\n",
    "        temp_Aij = temp_Aij[mask].reshape((num_j,num_j-1))\n",
    "        temp_Aij = np.tile(np.sum(temp_Aij, axis=1), num_j).reshape((num_j,num_j))\n",
    "        temp_Aij = temp_Aij[mask].reshape((-1,1))\n",
    "\n",
    "        temp_Aij = pd.DataFrame(np.hstack((temp_codes, temp_Aij)), columns = ['Code', 'Aij'])\n",
    "        X_Aij_df = pd.merge(X, temp_Aij, how = 'left', on =  ['Code'])\n",
    "\n",
    "        Aij = pd.to_numeric(X_Aij_df['Aij'].values).reshape((-1,1))\n",
    "\n",
    "    return Aij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "local-sauce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18881.77497771],\n",
       "       [20545.76577865],\n",
       "       [29964.34847772],\n",
       "       [ 7553.70956538],\n",
       "       [30972.31179077]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Aij1 = SpatialSmooth(5, X_df, 1, austria_shp, -1.35)\n",
    "Aij[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "critical-renaissance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99220.55946816],\n",
       "       [89299.76447806],\n",
       "       [13989.01559767],\n",
       "       [29308.82630006],\n",
       "       [27164.76253095]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Aij2 = SpatialSmooth2(5, X_df, 1, austria_shp, -1.35)\n",
    "Aij2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "functional-angle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99220.55946816],\n",
       "       [89299.76447806],\n",
       "       [13989.01559767],\n",
       "       [29308.82630006],\n",
       "       [27164.76253095]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Aij3 = SpatialSmooth3(5, X_df, 1, austria_shp, -1.35, is_Each = False)\n",
    "Aij3[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-revolution",
   "metadata": {},
   "source": [
    "As we could see, the results from `SpatialSmooth2()` and `SpatialSmooth3()` are the same because in the case of Austria, each origin is also a destination and `SpatialSmooth2()` is one special case of `SpatialSmooth3()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "median-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompeteDestination3(y, v1, v2, v3, X_df, pid, geomap, is_Spatial=True, is_Each =False, verbose=False):\n",
    "    \n",
    "    # build X\n",
    "    def build_X(v1, v2, v3, X_df, pid, geomap, is_Spatial, is_Each):\n",
    "        \n",
    "        Oi = X_df.iloc[:,v1]\n",
    "        Wj = X_df.iloc[:,v2]\n",
    "        Dij = X_df.iloc[:,v3]\n",
    "        X = np.column_stack((Oi, Wj, Dij))\n",
    "        \n",
    "        if is_Spatial == True:\n",
    "            #initialize the accissibility term with sigma set as -1\n",
    "            init_Aij = SpatialSmooth3(v2, X_df, pid, geomap, 1, is_Each)\n",
    "            X = np.hstack((X,init_Aij)) \n",
    "        return X\n",
    "    \n",
    "    X = build_X(v1, v2, v3, X_df, pid, geomap, is_Spatial, is_Each)\n",
    "\n",
    "    s_0 = np.log(np.mean(y))\n",
    "    eta = s_0.reshape((-1, 1))\n",
    "    s_old = np.zeros_like(X)\n",
    "    crit = 9999\n",
    "    sigma = np.inf\n",
    "    \n",
    "    # backfitting - inner loop\n",
    "    def backfit3(y, X, w, v2, X_df, pid, geomap, is_Spatial, is_Each, verbose):\n",
    "        n,k = X.shape\n",
    "        betas = _compute_betas_gwr(y, np.log(X), w.reshape((-1, 1)))[0]\n",
    "        #print(betas)\n",
    "        XB = np.multiply(betas.T, np.log(X))\n",
    "        yhat = np.dot(np.log(X), betas)\n",
    "        err = y.reshape((-1, 1)) - yhat\n",
    "        iters = 0\n",
    "        scores = []\n",
    "        delta = 1e6\n",
    "        tol = 1e-8\n",
    "        max_iter = 50\n",
    "        sig = np.inf\n",
    "        \n",
    "        if is_Spatial == True:\n",
    "            for iters in range(1, max_iter + 1):\n",
    "                new_XB = np.zeros_like(X)\n",
    "                params = np.zeros_like(betas)\n",
    "\n",
    "                for j in range(k):\n",
    "                    temp_y = XB[:, j].reshape((-1, 1))\n",
    "                    temp_y = temp_y + err.reshape((-1, 1))\n",
    "                    temp_X = np.log(X[:, j]).reshape((-1, 1))\n",
    "\n",
    "                    if j == k-1:\n",
    "                        score = lambda x: sm.OLS(temp_y, np.log(SpatialSmooth3(v2, X_df, pid, geomap, x, is_Each))).fit().aic\n",
    "                        sig  = golden_section(-6, 6, 0.38197, score, 1e-2, 50)[0]\n",
    "                        Aij = SpatialSmooth3(v2, X_df, pid, geomap, sig, is_Each)\n",
    "                        X[:, j] = Aij.flatten()\n",
    "                        temp_X = np.log(Aij).reshape((-1, 1))\n",
    "\n",
    "                    beta = _compute_betas_gwr(temp_y, temp_X, w.reshape((-1, 1)))[0]\n",
    "                    #print(beta)\n",
    "                    yhat = np.dot(temp_X, beta)\n",
    "                    new_XB[:, j] = yhat.flatten()\n",
    "                    err = (temp_y - yhat).reshape((-1, 1))\n",
    "                    params[j, :] = beta[0][0]\n",
    "    \n",
    "                num = np.sum((XB-new_XB)**2)\n",
    "                den = 1 + np.sum(np.sum(XB, axis=1)**2)\n",
    "                score = (num / den)\n",
    "                XB = new_XB\n",
    "        \n",
    "                scores.append(deepcopy(score))\n",
    "                delta = score\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"Current iteration:\", iters, \",SOC:\", np.round(score, 8))\n",
    "                if delta < tol:\n",
    "                    break\n",
    "                    \n",
    "        elif is_Spatial == False:\n",
    "            \n",
    "            for iters in range(1, max_iter + 1):\n",
    "                new_XB = np.zeros_like(X)\n",
    "                params = np.zeros_like(betas)\n",
    "\n",
    "                for j in range(k):\n",
    "                    temp_y = XB[:, j].reshape((-1, 1))\n",
    "                    temp_y = temp_y + err.reshape((-1, 1))\n",
    "                    temp_X = np.log(X[:, j]).reshape((-1, 1))\n",
    "                    beta = _compute_betas_gwr(temp_y, temp_X, w.reshape((-1, 1)))[0]\n",
    "                    #print(beta)\n",
    "                    yhat = np.dot(temp_X, beta)\n",
    "                    new_XB[:, j] = yhat.flatten()\n",
    "                    err = (temp_y - yhat).reshape((-1, 1))\n",
    "                    params[j, :] = beta[0][0]\n",
    "                    \n",
    "                num = np.sum((XB-new_XB)**2)\n",
    "                den = 1 + np.sum(np.sum(XB, axis=1)**2)\n",
    "                score = (num / den)\n",
    "                XB = new_XB\n",
    "        \n",
    "                scores.append(deepcopy(score))\n",
    "                delta = score\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"Current iteration:\", iters, \",SOC:\", np.round(score, 8))\n",
    "                if delta < tol:\n",
    "                    break\n",
    "\n",
    "        return params, X, sig\n",
    "    \n",
    "    #local scoring - outer loop \n",
    "    while crit > 1e-8:\n",
    "        \n",
    "        mu = np.exp(eta).reshape((-1, 1))\n",
    "        w = mu.reshape((-1,1))\n",
    "        z = eta + ((y.reshape((-1, 1)) - mu) / mu)\n",
    "        betas, X, sigma = backfit3(z, X, w, v2, X_df, pid, geomap,is_Spatial, is_Each, verbose)    \n",
    "        s_new = np.multiply(betas.T, np.log(X))\n",
    "        inner = np.sum((s_old - s_new)**2, axis=1)\n",
    "        num = np.sum(w*inner)\n",
    "        den = np.sum(w*np.sum((1 + s_old)**2, axis=1).reshape((-1, 1)))\n",
    "        crit = num / den\n",
    "        eta = np.sum(s_new, axis=1).reshape((-1, 1))\n",
    "        s_old = s_new\n",
    "        \n",
    "    return betas, eta, sigma\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "difficult-glucose",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Aij3 = SpatialSmooth3(5, X_df, 1, austria_shp, -1.35, is_Each =False)\n",
    "X3 = np.column_stack((Oi, Wj, Dij, Aij3))\n",
    "w = np.ones(72).reshape((-1,1))\n",
    "betas3 = iwls(flows.reshape((-1,1)), np.log(X3), family=Poisson(), offset=w.reshape((-1, 1)), y_fix=None, wi=w.reshape((-1, 1)))[0]\n",
    "f3 = np.exp(np.dot(np.log(X3), betas3) + np.random.normal(0, .0001, (72,1))).reshape((-1,1))\n",
    "start3 = time.time()\n",
    "betas_cd3, eta_cd3, sigma_cd3 = CompeteDestination3(f3, 4, 5, 6, X_df, 1, austria_shp, is_Spatial=True, is_Each = False, verbose=False)\n",
    "end3 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caroline-roots",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas_iwls3:\n",
      "[[ 0.62239105]\n",
      " [ 1.23615628]\n",
      " [-1.06479231]\n",
      " [-0.45072998]]\n",
      "betas_cd2:\n",
      "[[ 0.63758331]\n",
      " [ 1.38446578]\n",
      " [-1.04594236]\n",
      " [-0.59791932]]\n",
      "sigma_cd2:\n",
      "-1.05\n",
      "[[ 0.66013255]\n",
      " [ 0.64521874]\n",
      " [-1.11226874]\n",
      " [ 0.03381349]]\n",
      "sigma_cd3:\n",
      "5.96\n",
      "Runtime for ComepeteDestination2():\n",
      "26.739388465881348\n",
      "Runtime for ComepeteDestination3():\n",
      "442.38308119773865\n"
     ]
    }
   ],
   "source": [
    "print('betas_iwls3:', betas3, 'betas_cd2:', betas_cd2,'sigma_cd2:', sigma_cd2, betas_cd3,'sigma_cd3:', sigma_cd3, 'Runtime for ComepeteDestination2():', end2 - start2, 'Runtime for ComepeteDestination3():', end3 - start3, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-plaintiff",
   "metadata": {},
   "source": [
    "## Soulution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-organizer",
   "metadata": {},
   "source": [
    "1. assume that the dataframe X_df must have those columns: \n",
    "origin names/codes; \n",
    "destination names/codes;\n",
    "features of origin and destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "monthly-tours",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Data</th>\n",
       "      <th>Oi</th>\n",
       "      <th>Dj</th>\n",
       "      <th>Dij</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AT11</td>\n",
       "      <td>AT12</td>\n",
       "      <td>1131</td>\n",
       "      <td>4016</td>\n",
       "      <td>25741</td>\n",
       "      <td>103.001845</td>\n",
       "      <td>AT11AT12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AT11</td>\n",
       "      <td>AT13</td>\n",
       "      <td>1887</td>\n",
       "      <td>4016</td>\n",
       "      <td>26980</td>\n",
       "      <td>84.204666</td>\n",
       "      <td>AT11AT13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AT11</td>\n",
       "      <td>AT21</td>\n",
       "      <td>69</td>\n",
       "      <td>4016</td>\n",
       "      <td>4117</td>\n",
       "      <td>220.811933</td>\n",
       "      <td>AT11AT21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AT11</td>\n",
       "      <td>AT22</td>\n",
       "      <td>738</td>\n",
       "      <td>4016</td>\n",
       "      <td>8634</td>\n",
       "      <td>132.007480</td>\n",
       "      <td>AT11AT22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>AT11</td>\n",
       "      <td>AT31</td>\n",
       "      <td>98</td>\n",
       "      <td>4016</td>\n",
       "      <td>8193</td>\n",
       "      <td>214.511814</td>\n",
       "      <td>AT11AT31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Origin Destination  Data    Oi     Dj         Dij      Code\n",
       "1           1   AT11        AT12  1131  4016  25741  103.001845  AT11AT12\n",
       "2           2   AT11        AT13  1887  4016  26980   84.204666  AT11AT13\n",
       "3           3   AT11        AT21    69  4016   4117  220.811933  AT11AT21\n",
       "4           4   AT11        AT22   738  4016   8634  132.007480  AT11AT22\n",
       "5           5   AT11        AT31    98  4016   8193  214.511814  AT11AT31"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austria.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-literacy",
   "metadata": {},
   "source": [
    "2. we will create a dataframe setup_df based on `austria`. In setup_df, we will have those columns: Code(e.g.,'AT11AT31'); Origin; Destination; Oi; Wj; Dij; mk; dkj. And we can calculate Aij by doing a matrix element-wise multiplication:\n",
    "sum(X['mk']* (X['dkj'] ** sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "exempt-carroll",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_dist(v1, v2, X_df, pid, geomap):\n",
    "    '''\n",
    "    the index of the column 'Oi'\n",
    "    the index of the column 'Wj'\n",
    "    the index of the column storing the names/codes of the places in geomap\n",
    "    geomap: it must have a column storing the names/codes of the origins and destination in X_df. \n",
    "            And the name/codes must be same as those in the column 'Origin' and 'Destination' in X_df.\n",
    "    '''\n",
    "        \n",
    "    X_df['Code'] = X_df['Origin'] + X_df['Destination']\n",
    "    v1_name = X_df.columns[v1]\n",
    "    v2_name = X_df.columns[v2]\n",
    "    X = X_df.copy()\n",
    "\n",
    "    distances = sw.distance.DistanceBand.from_dataframe(geomap, threshold=99999, binary=False, alpha=1)\n",
    "    distances = distances.full()[0]\n",
    "    mask = distances!=0\n",
    "    distances = distances[mask].reshape((-1,1))\n",
    "    places = geomap.iloc[:,pid].values.reshape((-1,1))\n",
    "        \n",
    "    fcodes = [['DELETE']]\n",
    "    for place in places:\n",
    "        temp_places = np.tile(place, (len(places)-1,1))\n",
    "        other_places = places[places!= place].reshape((-1,1))\n",
    "        temp_fcodes = other_places + temp_places \n",
    "        fcodes = np.vstack((fcodes,temp_fcodes))\n",
    "                \n",
    "    fcodes = fcodes[fcodes != 'DELETE'].reshape((-1,1))\n",
    "        \n",
    "    distances_df = pd.DataFrame(np.hstack((fcodes, distances)), columns = ['Code', 'Distij'])\n",
    "    X_distances_df = pd.merge(X, distances_df, how = 'left', on =  ['Code'])\n",
    "    \n",
    "    X_distances_df = X_distances_df[['Code','Origin', 'Destination', v1_name, v2_name, 'Distij']] \n",
    "    return v2_name, X_distances_df\n",
    "\n",
    "def setup_Aij(v2_name, X_distances_df):\n",
    "    \n",
    "    '''\n",
    "    return:\n",
    "        a new dataframe with two new columns storing `mk` and `dkj` arrays with respect to each flow\n",
    "    ------------------------------------------------------------------------------------------------\n",
    "    We can calculate Aij based on the equation `Aij = sum(mk * (dkj ** sigma))`; \n",
    "    The implement is shown below:\n",
    "\n",
    "        X['Aij'] = ((X['mk']* (X['dkj'] ** sigma)).apply(lambda x: sum(x).item()))\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    X = X_distances_df.copy()\n",
    "\n",
    "    for temp_or in X['Origin']: \n",
    "    \n",
    "        #find all flows whose origin is temp_or\n",
    "        temp_df = X[X['Origin'] == temp_or]\n",
    "    \n",
    "        #all destinations whose origin is temp_or\n",
    "        temp_j = temp_df['Destination'].values\n",
    "    \n",
    "        #calculate aij for each destination temp_de\n",
    "        for temp_de in temp_j:\n",
    "        \n",
    "            #each flow's code\n",
    "            temp_code = temp_or + temp_de\n",
    "        \n",
    "            #alternative destination with respect to temp_de\n",
    "            alters = temp_j[temp_j != temp_de]\n",
    "        \n",
    "            #find distances between temp_de and all other alternative destinations and attractiveness of temp_de\n",
    "            temp_df2 = X[X['Origin'] == temp_de]\n",
    "            temp_df3 = temp_df2[temp_df2['Destination'].isin(alters)]\n",
    "        \n",
    "            mk = temp_df3[v2_name].values.reshape((-1,1))\n",
    "            dkj = temp_df3['Distij'].values.reshape((-1,1))\n",
    "            \n",
    "            # create a list containing mk and dkj repectively\n",
    "            \n",
    "            X.loc[X['Code'] == temp_code, 'mk'] = X['Code'].apply(lambda x: mk if x == temp_code else None)\n",
    "            X.loc[X['Code'] == temp_code, 'dkj'] = X['Code'].apply(lambda x: dkj if x == temp_code else None)\n",
    " \n",
    "    return X\n",
    "\n",
    "def SpatialSmooth(setup_df, sigma):\n",
    "    X = setup_df.copy()\n",
    "    X['Aij'] = ((X['mk']* (X['dkj'] ** sigma)).apply(lambda x: sum(x).item()))\n",
    "    Aijs = pd.to_numeric(X['Aij'].values).reshape((-1,1))\n",
    "    \n",
    "    return Aijs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "color-worse",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Oi</th>\n",
       "      <th>Dj</th>\n",
       "      <th>Distij</th>\n",
       "      <th>mk</th>\n",
       "      <th>dkj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT11AT12</td>\n",
       "      <td>AT11</td>\n",
       "      <td>AT12</td>\n",
       "      <td>4016</td>\n",
       "      <td>25741</td>\n",
       "      <td>1.060975</td>\n",
       "      <td>[[26980], [4117], [8634], [8193], [4902], [395...</td>\n",
       "      <td>[[0.6287635503694933], [2.3683513544769976], [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Code Origin Destination    Oi     Dj    Distij  \\\n",
       "0  AT11AT12   AT11        AT12  4016  25741  1.060975   \n",
       "\n",
       "                                                  mk  \\\n",
       "0  [[26980], [4117], [8634], [8193], [4902], [395...   \n",
       "\n",
       "                                                 dkj  \n",
       "0  [[0.6287635503694933], [2.3683513544769976], [...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dij = setup_dist(v1 = 4, v2 = 5, X_df = austria, pid = 1, geomap = austria_shp)[1]['Distij'].astype(float)\n",
    "v2_name, setup_df = setup_dist(4, 5, austria, 1, austria_shp)\n",
    "setup_df = setup_Aij(v2_name, setup_df)\n",
    "setup_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "reasonable-flooring",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SpatialGAM(y, v1, v2, X_df, pid, geomap, is_Spatial = True, verbose = False):\n",
    "    \n",
    "    def setup_dist(v1, v2, X_df, pid, geomap):\n",
    "        \n",
    "        X_df['Code'] = X_df['Origin'] + X_df['Destination']\n",
    "        v1_name = X_df.columns[v1]\n",
    "        v2_name = X_df.columns[v2]\n",
    "        X = X_df.copy()\n",
    "\n",
    "        distances = sw.distance.DistanceBand.from_dataframe(geomap, threshold=99999, binary=False, alpha=1)\n",
    "        distances = distances.full()[0]\n",
    "        mask = distances!=0\n",
    "        distances = distances[mask].reshape((-1,1))\n",
    "        places = geomap.iloc[:,pid].values.reshape((-1,1))\n",
    "        \n",
    "        fcodes = [['DELETE']]\n",
    "        for place in places:\n",
    "            temp_places = np.tile(place, (len(places)-1,1))\n",
    "            other_places = places[places!= place].reshape((-1,1))\n",
    "            temp_fcodes = other_places + temp_places \n",
    "            fcodes = np.vstack((fcodes,temp_fcodes))\n",
    "                \n",
    "        fcodes = fcodes[fcodes != 'DELETE'].reshape((-1,1))\n",
    "        \n",
    "        distances_df = pd.DataFrame(np.hstack((fcodes, distances)), columns = ['Code', 'Distij'])\n",
    "        X_distances_df = pd.merge(X, distances_df, how = 'left', on =  ['Code'])\n",
    "    \n",
    "        X_distances_df = X_distances_df[['Code','Origin', 'Destination', v1_name, v2_name, 'Distij']] \n",
    "        \n",
    "        return v2_name, X_distances_df\n",
    "\n",
    "    def setup_Aij(v2_name, X_distances_df):\n",
    "    \n",
    "        X = X_distances_df.copy()\n",
    "\n",
    "        for temp_or in X['Origin']: \n",
    "    \n",
    "            #find all flows whose origin is temp_or\n",
    "            temp_df = X[X['Origin'] == temp_or]\n",
    "    \n",
    "            #all destinations whose origin is temp_or\n",
    "            temp_j = temp_df['Destination'].values\n",
    "    \n",
    "            #calculate aij for each destination temp_de\n",
    "            for temp_de in temp_j:\n",
    "        \n",
    "                #each flow's code\n",
    "                temp_code = temp_or + temp_de\n",
    "        \n",
    "                #alternative destination with respect to temp_de\n",
    "                alters = temp_j[temp_j != temp_de]\n",
    "        \n",
    "                #find distances between temp_de and all other alternative destinations and attractiveness of temp_de\n",
    "                temp_df2 = X[X['Origin'] == temp_de]\n",
    "                temp_df3 = temp_df2[temp_df2['Destination'].isin(alters)]\n",
    "        \n",
    "                mk = temp_df3[v2_name].values.reshape((-1,1))\n",
    "                dkj = temp_df3['Distij'].values.reshape((-1,1))\n",
    "            \n",
    "                # create a list containing mk and dkj repectively\n",
    "                X.loc[X['Code'] == temp_code, 'mk'] = X['Code'].apply(lambda x: mk if x == temp_code else None)\n",
    "                X.loc[X['Code'] == temp_code, 'dkj'] = X['Code'].apply(lambda x: dkj if x == temp_code else None)\n",
    "\n",
    "        return X #setup_df\n",
    "    \n",
    "    def SpatialSmooth(setup_df, sigma):\n",
    "        X = setup_df.copy()\n",
    "        X['Aij'] = ((X['mk']* (X['dkj'] ** sigma)).apply(lambda x: sum(x).item()))\n",
    "        Aijs = pd.to_numeric(X['Aij'].values).reshape((-1,1))\n",
    "        \n",
    "        return Aijs\n",
    "\n",
    "    # build X\n",
    "    def build_X(v1, v2, X_df, pid, geomap, is_Spatial):\n",
    "        \n",
    "        v1_name = X_df.columns[v1]\n",
    "        v2_name, setup_df = setup_dist(v1, v2, X_df, pid, geomap)\n",
    "        setup_df = setup_Aij(v2_name, setup_df)\n",
    "        \n",
    "        Oi = pd.to_numeric(setup_df[v1_name].values).reshape((-1,1))\n",
    "        Wj = pd.to_numeric(setup_df[v2_name].values).reshape((-1,1))\n",
    "        Dij = pd.to_numeric(setup_df['Distij'].values).reshape((-1,1)) #X_df.iloc[:,v3]\n",
    "        X = np.column_stack((Oi, Wj, Dij))\n",
    "         \n",
    "        if is_Spatial == True:\n",
    "            #initialize the accissibility term with sigma set as -1\n",
    "            init_Aij = SpatialSmooth(setup_df, -1)\n",
    "            X = np.column_stack((Oi, Wj, Dij, init_Aij))\n",
    "        \n",
    "        return X, setup_df\n",
    "    \n",
    "    # backfitting - inner loop\n",
    "    def backfit(y, X, w, setup_df, is_Spatial, verbose):\n",
    "        n,k = X.shape\n",
    "        \n",
    "        betas = _compute_betas_gwr(y, np.log(X), w.reshape((-1, 1)))[0]\n",
    "        # sm.OLS(y, np.log(X) * w.reshape((-1,1))).fit().params.reshape((-1,1))\n",
    "        # print(betas)\n",
    "        XB = np.multiply(betas.T, np.log(X))\n",
    "        yhat = np.dot(np.log(X), betas)\n",
    "        err = y.reshape((-1, 1)) - yhat\n",
    "        iters = 0\n",
    "        scores = []\n",
    "        delta = 1e6\n",
    "        tol = 1e-8\n",
    "        max_iter = 50\n",
    "        sig = np.inf\n",
    "        \n",
    "        if is_Spatial == True:\n",
    "            for iters in range(1, max_iter + 1):\n",
    "                new_XB = np.zeros_like(X)\n",
    "                params = np.zeros_like(betas)\n",
    "\n",
    "                for j in range(k):\n",
    "                    temp_y = XB[:, j].reshape((-1, 1))\n",
    "                    temp_y = temp_y + err.reshape((-1, 1))\n",
    "                    temp_X = np.log(X[:, j]).reshape((-1, 1))\n",
    "\n",
    "                    if j == k-1:\n",
    "                        score = lambda x: sm.OLS(temp_y, np.log(SpatialSmooth(setup_df, x))).fit().aic\n",
    "                        sig  = golden_section(-6, 6, 0.38197, score, 1e-2, 50)[0]\n",
    "                        Aij = SpatialSmooth(setup_df, sig)\n",
    "                        X[:, j] = Aij.flatten()\n",
    "                        temp_X = np.log(Aij).reshape((-1,1))\n",
    "\n",
    "                    beta = _compute_betas_gwr(temp_y, temp_X, w.reshape((-1, 1)))[0]\n",
    "                    #sm.OLS(temp_y, temp_X * w.reshape((-1,1))).fit().params.reshape((-1,1))\n",
    "                    #print(beta)\n",
    "                    yhat = np.dot(temp_X, beta)\n",
    "                    new_XB[:, j] = yhat.flatten()\n",
    "                    err = (temp_y - yhat).reshape((-1, 1))\n",
    "                    params[j, :] = beta[0][0]\n",
    "    \n",
    "                num = np.sum((XB-new_XB)**2)\n",
    "                den = 1 + np.sum(np.sum(XB, axis=1)**2)\n",
    "                score = (num / den)\n",
    "                XB = new_XB\n",
    "        \n",
    "                scores.append(deepcopy(score))\n",
    "                delta = score\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"Current iteration:\", iters, \",SOC:\", np.round(score, 8))\n",
    "                if delta < tol:\n",
    "                    break\n",
    "                    \n",
    "        elif is_Spatial == False:\n",
    "            for iters in range(1, max_iter + 1):\n",
    "                new_XB = np.zeros_like(X)\n",
    "                params = np.zeros_like(betas)\n",
    "\n",
    "                for j in range(k):\n",
    "                    temp_y = XB[:, j].reshape((-1, 1))\n",
    "                    temp_y = temp_y + err.reshape((-1, 1))\n",
    "                    temp_X = np.log(X[:, j]).reshape((-1, 1))\n",
    "                    beta = _compute_betas_gwr(temp_y, temp_X, w.reshape((-1, 1)))[0]\n",
    "                    #print(beta)\n",
    "                    yhat = np.dot(temp_X, beta)\n",
    "                    new_XB[:, j] = yhat.flatten()\n",
    "                    err = (temp_y - yhat).reshape((-1, 1))\n",
    "                    params[j, :] = beta[0][0]\n",
    "                    \n",
    "                num = np.sum((XB-new_XB)**2)\n",
    "                den = 1 + np.sum(np.sum(XB, axis=1)**2)\n",
    "                score = (num / den)\n",
    "                XB = new_XB\n",
    "        \n",
    "                scores.append(deepcopy(score))\n",
    "                delta = score\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"Current iteration:\", iters, \",SOC:\", np.round(score, 8))\n",
    "                if delta < tol:\n",
    "                    break\n",
    "\n",
    "        return params, X, sig\n",
    "    \n",
    "\n",
    "    X, setup_df = build_X(v1, v2, X_df, pid, geomap, is_Spatial)\n",
    "    s_0 = np.log(np.mean(y))\n",
    "    eta = s_0.reshape((-1, 1))\n",
    "    s_old = np.zeros_like(X)\n",
    "    crit = 9999\n",
    "    sigma = 9999\n",
    "    \n",
    "    #local scoring - outer loop \n",
    "    while crit > 1e-8:\n",
    "        \n",
    "        mu = np.exp(eta).reshape((-1, 1))\n",
    "        w = mu.reshape((-1,1))\n",
    "        z = eta + ((y.reshape((-1, 1)) - mu) / mu)\n",
    "        betas, X, sigma = backfit(z, X, w, setup_df, is_Spatial, verbose)\n",
    "        s_new = np.multiply(betas.T, np.log(X))\n",
    "        inner = np.sum((s_old - s_new)**2, axis=1)\n",
    "        num = np.sum(w*inner)\n",
    "        den = np.sum(w*np.sum((1 + s_old)**2, axis=1).reshape((-1, 1)))\n",
    "        crit = num / den\n",
    "        eta = np.sum(s_new, axis=1).reshape((-1, 1))\n",
    "        s_old = s_new\n",
    "        \n",
    "    return betas, eta, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "inner-jaguar",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Aij4 = SpatialSmooth(setup_df, -1.35)\n",
    "X4 = np.column_stack((Oi, Wj, Dij, Aij4))\n",
    "w = np.ones(72).reshape((-1,1))\n",
    "betas4 = iwls(flows.reshape((-1,1)), np.log(X4), family=Poisson(), offset=w.reshape((-1, 1)), y_fix=None, wi=w.reshape((-1, 1)))[0]\n",
    "f4 = np.exp(np.dot(np.log(X4), betas) + np.random.normal(0, .0001, (72,1))).reshape((-1,1))\n",
    "start4 = time.time()\n",
    "betas_cd4, eta_cd4, sigma_cd4 = SpatialGAM(f4, 4, 5, austria, 1, austria_shp, is_Spatial = True, verbose = False)\n",
    "end4 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "external-lingerie",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas_iwls4:\n",
      "[[ 0.56357089]\n",
      " [ 0.96364052]\n",
      " [-0.75495023]\n",
      " [-0.62447807]]\n",
      "betas_cd4:\n",
      "[[ 0.56358224]\n",
      " [ 0.96367122]\n",
      " [-0.75493081]\n",
      " [-0.62451253]]\n",
      "sigma_cd4:\n",
      "-1.35\n",
      "Runtime for SpatialGAM():\n",
      "16.595179319381714\n"
     ]
    }
   ],
   "source": [
    "print('betas_iwls4:', betas4, 'betas_cd4:', betas_cd4,'sigma_cd4:', sigma_cd4, 'Runtime for SpatialGAM():', end4 - start4,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-assessment",
   "metadata": {},
   "source": [
    "## Backup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-ozone",
   "metadata": {},
   "source": [
    "### Codes below could also be found in `CDM+GAM_new.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-discussion",
   "metadata": {},
   "source": [
    "Codes below worked well. The way we calculate the accessibility in `SpatialSmooth()` and `CompeteDestination()` below is based on the codes `access()` from the file 'PossionGAM.py' and 'PossionGAM.ipynb', which Dr.Taylor Oshan sent to me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-bloom",
   "metadata": {},
   "source": [
    "## Spatial Smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unsigned-pregnancy",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SpatialSmooth(m, X_df, pid, geomap, sigma):\n",
    "    \n",
    "    '''\n",
    "    m: the index of the column storing the quality of destination\n",
    "    X_df: the dataframe containing the predictors columns; \n",
    "          by default, we assume X_df has the columns with those names:\n",
    "            `Origin`: the name or code of origin\n",
    "            `Destination`: the name or code of destination\n",
    "            `Code`: `Origi` + `Destination` \n",
    "            `Oi`, 'Wj', 'Dij': No need to have the same column name\n",
    "            `Dij`: In the future, users do not need to provide it, the distance between origin ande destination in a flow will be calculate by using geomap automatically\n",
    "    \n",
    "    pid: the index of the column storing the name of the place in geomap # NUTS_ID, 1 in austrai_shp\n",
    "    geomap: the file with coordinates information to calculate the distance\n",
    "    sigma: sigma in the formula of accessibility in CDM\n",
    "    '''\n",
    "    Aij = np.zeros_like(X_df.iloc[:,m]).reshape((-1,1))\n",
    "    \n",
    "    X = X_df.copy()\n",
    "        \n",
    "    #obtain the quality of all destinations, mk\n",
    "    j_df = X.drop_duplicates(subset = ['Destination'])\n",
    "    j_df = j_df.set_index(j_df['Destination']).sort_index()\n",
    "    mk = j_df.iloc[:,m].values.reshape((-1,1))\n",
    "        \n",
    "    #obtain all destinations\n",
    "    all_places = geomap.iloc[:,pid].values.reshape((-1,1)) \n",
    "    num_j = len(all_places)\n",
    "        \n",
    "    #create the flow codes\n",
    "    temp_codes = [['DELETE']]\n",
    "        \n",
    "    for place in all_places:\n",
    "        temp_places = np.tile(place, (num_j-1,1))\n",
    "        other_places = all_places[all_places != place].reshape((-1,1))\n",
    "        r = temp_places + other_places\n",
    "        temp_codes = np.vstack((temp_codes,r))\n",
    "                \n",
    "    temp_codes = temp_codes[temp_codes != 'DELETE'].reshape((-1,1))\n",
    "     \n",
    "    #calculate the accessibility\n",
    "    W = sw.distance.DistanceBand.from_dataframe(geomap, threshold=99999, binary=False, alpha=sigma)\n",
    "    W = W.full()[0]\n",
    "    mask = W!=0\n",
    "    temp_Aij = (W * mk)\n",
    "    temp_Aij = temp_Aij[mask].reshape((num_j,num_j-1))\n",
    "    temp_Aij = np.tile(np.sum(temp_Aij, axis=1), num_j).reshape((num_j,num_j))\n",
    "    temp_Aij = temp_Aij[mask].reshape((-1,1))\n",
    "\n",
    "    temp_Aij = pd.DataFrame(np.hstack((temp_codes, temp_Aij)), columns = ['Code', 'Aij'])\n",
    "\n",
    "    X_Aij_df = pd.merge(X, temp_Aij, how = 'left', on =  ['Code'])\n",
    "\n",
    "    Aij = pd.to_numeric(X_Aij_df['Aij'].values).reshape((-1,1))\n",
    "\n",
    "    return Aij"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-entrance",
   "metadata": {},
   "source": [
    "## CompeteDestination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "valued-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompeteDestination(y, v1, v2, v3, X_df, pid, geomap, is_Spatial=True, verbose=False):\n",
    "    \n",
    "    '''\n",
    "    y: the array of the response variable\n",
    "    v1: the index of the Oi column\n",
    "    v2: the index of the Wj column\n",
    "    v3: the index of the Dij column\n",
    "    X_df: the dataframe containing the predictors columns; \n",
    "          by default, we assume X_df has the columns with those names:\n",
    "            `Origin`: the name or code of origin\n",
    "            `Destination`: the name or code of destination\n",
    "            `Code`: `Origi` + `Destination` \n",
    "            `Oi`, 'Wj', 'Dij': No need to have the same column name\n",
    "            `Dij`: In the future, users do not need to provide it, the distance between origin ande destination in a flow will be calculate by using geomap automatically\n",
    "            \n",
    "    geomap: the file with coordinate info of origin and destination\n",
    "            must have a column storing the name or code of origin and destination\n",
    "    pid: the index of the must-have column in geomap\n",
    "    is_Spatial: whether we need to create a spatial smooth, by default it is true\n",
    "    '''\n",
    "    \n",
    "    # build X\n",
    "    def build_X(v1, v2, v3, X_df, pid, geomap, is_Spatial):\n",
    "        \n",
    "        Oi = X_df.iloc[:,v1]\n",
    "        Wj = X_df.iloc[:,v2]\n",
    "        Dij = X_df.iloc[:,v3]\n",
    "        X = np.column_stack((Oi, Wj, Dij))\n",
    "        \n",
    "        if is_Spatial == True:\n",
    "            #initialize the accissibility term with sigma set as -1\n",
    "            init_Aij = SpatialSmooth(v2, X_df, pid, geomap, -1)\n",
    "            X = np.hstack((X,init_Aij)) \n",
    "        return X\n",
    "    \n",
    "    X = build_X(v1, v2, v3, X_df, pid, geomap, is_Spatial)\n",
    "\n",
    "    s_0 = np.log(np.mean(y))\n",
    "    eta = s_0.reshape((-1, 1))\n",
    "    s_old = np.zeros_like(X)\n",
    "    crit = 9999\n",
    "    sigma = np.inf\n",
    "    \n",
    "    # backfitting - inner loop\n",
    "    def backfit(y, X, w, v2, X_df, pid, geomap, is_Spatial, verbose):\n",
    "        n,k = X.shape\n",
    "        betas = _compute_betas_gwr(y, np.log(X), w.reshape((-1, 1)))[0]\n",
    "        #print(betas)\n",
    "        XB = np.multiply(betas.T, np.log(X))\n",
    "        yhat = np.dot(np.log(X), betas)\n",
    "        err = y.reshape((-1, 1)) - yhat\n",
    "        iters = 0\n",
    "        scores = []\n",
    "        delta = 1e6\n",
    "        tol = 1e-8\n",
    "        max_iter = 50\n",
    "        sig = 9999\n",
    "        \n",
    "        if is_Spatial == True:\n",
    "            for iters in range(1, max_iter + 1):\n",
    "                new_XB = np.zeros_like(X)\n",
    "                params = np.zeros_like(betas)\n",
    "\n",
    "                for j in range(k):\n",
    "                    temp_y = XB[:, j].reshape((-1, 1))\n",
    "                    temp_y = temp_y + err.reshape((-1, 1))\n",
    "                    temp_X = np.log(X[:, j]).reshape((-1, 1))\n",
    "\n",
    "                    if j == k-1:\n",
    "                        score = lambda x: sm.OLS(temp_y, np.log(SpatialSmooth(v2, X_df, pid, geomap, x))).fit().aic\n",
    "                        sig  = golden_section(-6, 6, 0.38197, score, 1e-2, 50)[0]\n",
    "                        Aij = SpatialSmooth(v2, X_df, pid, geomap, sig)\n",
    "                        X[:, j] = Aij.flatten()\n",
    "                        temp_X = np.log(Aij).reshape((-1, 1))\n",
    "\n",
    "                    beta = _compute_betas_gwr(temp_y, temp_X, w.reshape((-1, 1)))[0]\n",
    "                    #print(beta)\n",
    "                    yhat = np.dot(temp_X, beta)\n",
    "                    new_XB[:, j] = yhat.flatten()\n",
    "                    err = (temp_y - yhat).reshape((-1, 1))\n",
    "                    params[j, :] = beta[0][0]\n",
    "    \n",
    "                num = np.sum((XB-new_XB)**2)\n",
    "                den = 1 + np.sum(np.sum(XB, axis=1)**2)\n",
    "                score = (num / den)\n",
    "                XB = new_XB\n",
    "        \n",
    "                scores.append(deepcopy(score))\n",
    "                delta = score\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"Current iteration:\", iters, \",SOC:\", np.round(score, 8))\n",
    "                if delta < tol:\n",
    "                    break\n",
    "                    \n",
    "        elif is_Spatial == False:\n",
    "            for iters in range(1, max_iter + 1):\n",
    "                new_XB = np.zeros_like(X)\n",
    "                params = np.zeros_like(betas)\n",
    "\n",
    "                for j in range(k):\n",
    "                    temp_y = XB[:, j].reshape((-1, 1))\n",
    "                    temp_y = temp_y + err.reshape((-1, 1))\n",
    "                    temp_X = np.log(X[:, j]).reshape((-1, 1))\n",
    "                    beta = _compute_betas_gwr(temp_y, temp_X, w.reshape((-1, 1)))[0]\n",
    "                    #print(beta)\n",
    "                    yhat = np.dot(temp_X, beta)\n",
    "                    new_XB[:, j] = yhat.flatten()\n",
    "                    err = (temp_y - yhat).reshape((-1, 1))\n",
    "                    params[j, :] = beta[0][0]\n",
    "                    \n",
    "                num = np.sum((XB-new_XB)**2)\n",
    "                den = 1 + np.sum(np.sum(XB, axis=1)**2)\n",
    "                score = (num / den)\n",
    "                XB = new_XB\n",
    "        \n",
    "                scores.append(deepcopy(score))\n",
    "                delta = score\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"Current iteration:\", iters, \",SOC:\", np.round(score, 8))\n",
    "                if delta < tol:\n",
    "                    break\n",
    "\n",
    "        return params, X, sig\n",
    "    \n",
    "    #local scoring - outer loop \n",
    "    while crit > 1e-8:\n",
    "        mu = np.exp(eta).reshape((-1, 1))\n",
    "        w = mu.reshape((-1,1))\n",
    "        z = eta + ((y.reshape((-1, 1)) - mu) / mu)\n",
    "        betas, X, sigma = backfit(z, X, w, v2, X_df, pid, geomap,is_Spatial, verbose)\n",
    "        s_new = np.multiply(betas.T, np.log(X))\n",
    "        inner = np.sum((s_old - s_new)**2, axis=1)\n",
    "        num = np.sum(w*inner)\n",
    "        den = np.sum(w*np.sum((1 + s_old)**2, axis=1).reshape((-1, 1)))\n",
    "        crit = num / den\n",
    "        eta = np.sum(s_new, axis=1).reshape((-1, 1))\n",
    "        s_old = s_new\n",
    "        \n",
    "    return betas, eta, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-announcement",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "compound-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "austria = pd.read_csv('Data/austria.csv')\n",
    "austria_shp = gp.read_file('Data/austria.shp')\n",
    "Dja = austria['Dj'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "optical-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "austria = austria[austria['Origin'] != austria['Destination']]\n",
    "flows = austria['Data'].values \n",
    "Oi = austria['Oi'].values \n",
    "Wj = austria['Dj'].values \n",
    "Dij = austria['Dij'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "forbidden-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = austria.copy()\n",
    "X_df['Code'] = X_df['Origin'] + X_df['Destination']\n",
    "X_df = X_df.loc[:, ~X_df.columns.str.contains('^Unnamed')]\n",
    "X_df = X_df[['Code','Origin', 'Destination', 'Data', 'Oi', 'Dj', 'Dij']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dirty-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "Aij = SpatialSmooth(5, X_df, 1, austria_shp, -1.35)\n",
    "X = np.column_stack((Oi, Wj, Dij, Aij))\n",
    "w = np.ones(72).reshape((-1,1))\n",
    "betas = iwls(flows.reshape((-1,1)), np.log(X), family=Poisson(), offset=w.reshape((-1, 1)), y_fix=None, wi=w.reshape((-1, 1)))[0]\n",
    "f = np.exp(np.dot(np.log(X), betas))# + np.random.normal(0, .0001, (72,1))).reshape((-1,1))\n",
    "betas_cd, eta_cd, sigma_cd = CompeteDestination(f, 4, 5, 6, X_df, 1, austria_shp, is_Spatial=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mental-winning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas_iwls:\n",
      "[[ 0.71369558]\n",
      " [ 0.72409961]\n",
      " [-1.0584376 ]\n",
      " [-0.08370744]]\n",
      "betas_cd:\n",
      "[[ 0.71369558]\n",
      " [ 0.72409961]\n",
      " [-1.0584376 ]\n",
      " [-0.08370744]]\n",
      "sigma_cd:\n",
      "-1.35\n"
     ]
    }
   ],
   "source": [
    "print('betas_iwls:', betas, 'betas_cd:', betas_cd,'sigma_cd:', sigma_cd, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-agenda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
