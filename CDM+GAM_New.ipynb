{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "australian-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from spglm.iwls import iwls, _compute_betas_gwr\n",
    "from spglm.family import *\n",
    "from mgwr.search import golden_section\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import geopandas as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import libpysal.weights as sw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-arabic",
   "metadata": {},
   "source": [
    "## Spatial Smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "backed-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpatialSmooth(m, X_df, pid, geomap, sigma):\n",
    "    \n",
    "    '''\n",
    "    m: the index of the column storing the quality of destination\n",
    "    X_df: the dataframe containing the predictors columns; \n",
    "          by default, we assume X_df has the columns with those names:\n",
    "            `Origin`: the name or code of origin\n",
    "            `Destination`: the name or code of destination\n",
    "            `Code`: `Origi` + `Destination` \n",
    "            `Oi`, 'Wj', 'Dij': No need to have the same column name\n",
    "            `Dij`: In the future, users do not need to provide it, the distance between origin ande destination in a flow will be calculate by using geomap automatically\n",
    "    \n",
    "    pid: the index of the column storing the name of the place in geomap # NUTS_ID, 1 in austrai_shp\n",
    "    geomap: the file with coordinates information to calculate the distance\n",
    "    sigma: sigma in the formula of accessibility in CDM\n",
    "    '''\n",
    "    Aij = np.zeros_like(X_df.iloc[:,m]).reshape((-1,1))\n",
    "    \n",
    "    X = X_df.copy()\n",
    "        \n",
    "    #obtain the quality of all destinations, mk\n",
    "    j_df = X.drop_duplicates(subset = ['Destination'])\n",
    "    j_df = j_df.set_index(j_df['Destination']).sort_index()\n",
    "    mk = j_df.iloc[:,m].values.reshape((-1,1))\n",
    "        \n",
    "    #obtain all destinations\n",
    "    all_places = geomap.iloc[:,pid].values.reshape((-1,1)) \n",
    "    num_j = len(all_places)\n",
    "        \n",
    "    #create the flow codes\n",
    "    temp_codes = [['DELETE']]\n",
    "        \n",
    "    for place in all_places:\n",
    "        temp_places = np.tile(place, (num_j-1,1))\n",
    "        other_places = all_places[all_places != place].reshape((-1,1))\n",
    "        r = temp_places + other_places\n",
    "        temp_codes = np.vstack((temp_codes,r))\n",
    "                \n",
    "    temp_codes = temp_codes[temp_codes != 'DELETE'].reshape((-1,1))\n",
    "     \n",
    "    #calculate the accessibility\n",
    "    W = sw.distance.DistanceBand.from_dataframe(geomap, threshold=99999, binary=False, alpha=sigma)\n",
    "    W = W.full()[0]\n",
    "    mask = W!=0\n",
    "    temp_Aij = (W * mk)\n",
    "    temp_Aij = temp_Aij[mask].reshape((num_j,num_j-1))\n",
    "    temp_Aij = np.tile(np.sum(temp_Aij, axis=1), num_j).reshape((num_j,num_j))\n",
    "    temp_Aij = temp_Aij[mask].reshape((-1,1))\n",
    "\n",
    "    temp_Aij = pd.DataFrame(np.hstack((temp_codes, temp_Aij)), columns = ['Code', 'Aij'])\n",
    "\n",
    "    X_Aij_df = pd.merge(X, temp_Aij, how = 'left', on =  ['Code'])\n",
    "\n",
    "    Aij = pd.to_numeric(X_Aij_df['Aij'].values).reshape((-1,1))\n",
    "\n",
    "    return Aij"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-screw",
   "metadata": {},
   "source": [
    "## CompeteDestination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "invalid-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompeteDestination(y, v1, v2, v3, X_df, pid, geomap, is_Spatial=True, verbose=False):\n",
    "    \n",
    "    '''\n",
    "    y: the array of the response variable\n",
    "    v1: the index of the Oi column\n",
    "    v2: the index of the Wj column\n",
    "    v3: the index of the Dij column\n",
    "    X_df: the dataframe containing the predictors columns; \n",
    "          by default, we assume X_df has the columns with those names:\n",
    "            `Origin`: the name or code of origin\n",
    "            `Destination`: the name or code of destination\n",
    "            `Code`: `Origi` + `Destination` \n",
    "            `Oi`, 'Wj', 'Dij': No need to have the same column name\n",
    "            `Dij`: In the future, users do not need to provide it, the distance between origin ande destination in a flow will be calculate by using geomap automatically\n",
    "            \n",
    "    geomap: the file with coordinate info of origin and destination\n",
    "            must have a column storing the name or code of origin and destination\n",
    "    pid: the index of the must-have column in geomap\n",
    "    is_Spatial: whether we need to create a spatial smooth, by default it is true\n",
    "    '''\n",
    "    \n",
    "    # build X\n",
    "    def build_X(v1, v2, v3, X_df, pid, geomap, is_Spatial):\n",
    "        \n",
    "        Oi = X_df.iloc[:,v1]\n",
    "        Wj = X_df.iloc[:,v2]\n",
    "        Dij = X_df.iloc[:,v3]\n",
    "        X = np.column_stack((Oi, Wj, Dij))\n",
    "        \n",
    "        if is_Spatial == True:\n",
    "            #initialize the accissibility term with sigma set as -1\n",
    "            init_Aij = SpatialSmooth(v2, X_df, pid, geomap, -1)\n",
    "            X = np.hstack((X,init_Aij)) \n",
    "        return X\n",
    "    \n",
    "    X = build_X(v1, v2, v3, X_df, pid, geomap, is_Spatial)\n",
    "\n",
    "    s_0 = np.log(np.mean(y))\n",
    "    eta = s_0.reshape((-1, 1))\n",
    "    s_old = np.zeros_like(X)\n",
    "    crit = 9999\n",
    "    sigma = np.inf\n",
    "    \n",
    "    # backfitting - inner loop\n",
    "    def backfit(y, X, w, v2, X_df, pid, geomap, is_Spatial, verbose):\n",
    "        n,k = X.shape\n",
    "        betas = _compute_betas_gwr(y, np.log(X), w.reshape((-1, 1)))[0]\n",
    "        #print(betas)\n",
    "        XB = np.multiply(betas.T, np.log(X))\n",
    "        yhat = np.dot(np.log(X), betas)\n",
    "        err = y.reshape((-1, 1)) - yhat\n",
    "        iters = 0\n",
    "        scores = []\n",
    "        delta = 1e6\n",
    "        tol = 1e-8\n",
    "        max_iter = 50\n",
    "        sig = np.inf\n",
    "        \n",
    "        if is_Spatial == True:\n",
    "            for iters in range(1, max_iter + 1):\n",
    "                new_XB = np.zeros_like(X)\n",
    "                params = np.zeros_like(betas)\n",
    "\n",
    "                for j in range(k):\n",
    "                    temp_y = XB[:, j].reshape((-1, 1))\n",
    "                    temp_y = temp_y + err.reshape((-1, 1))\n",
    "                    temp_X = np.log(X[:, j]).reshape((-1, 1))\n",
    "\n",
    "                    if j == k-1:\n",
    "                        score = lambda x: sm.OLS(temp_y, np.log(SpatialSmooth(v2, X_df, pid, geomap, x))).fit().aic\n",
    "                        sig  = golden_section(-6, 6, 0.38197, score, 1e-2, 50)[0]\n",
    "                        Aij = SpatialSmooth(v2, X_df, pid, geomap, sig)\n",
    "                        X[:, j] = Aij.flatten()\n",
    "                        temp_X = np.log(Aij).reshape((-1, 1))\n",
    "\n",
    "                    beta = _compute_betas_gwr(temp_y, temp_X, w.reshape((-1, 1)))[0]\n",
    "                    #print(beta)\n",
    "                    yhat = np.dot(temp_X, beta)\n",
    "                    new_XB[:, j] = yhat.flatten()\n",
    "                    err = (temp_y - yhat).reshape((-1, 1))\n",
    "                    params[j, :] = beta[0][0]\n",
    "    \n",
    "                num = np.sum((XB-new_XB)**2)\n",
    "                den = 1 + np.sum(np.sum(XB, axis=1)**2)\n",
    "                score = (num / den)\n",
    "                XB = new_XB\n",
    "        \n",
    "                scores.append(deepcopy(score))\n",
    "                delta = score\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"Current iteration:\", iters, \",SOC:\", np.round(score, 8))\n",
    "                if delta < tol:\n",
    "                    break\n",
    "                    \n",
    "        elif is_Spatial == False:\n",
    "            for iters in range(1, max_iter + 1):\n",
    "                new_XB = np.zeros_like(X)\n",
    "                params = np.zeros_like(betas)\n",
    "\n",
    "                for j in range(k):\n",
    "                    temp_y = XB[:, j].reshape((-1, 1))\n",
    "                    temp_y = temp_y + err.reshape((-1, 1))\n",
    "                    temp_X = np.log(X[:, j]).reshape((-1, 1))\n",
    "                    beta = _compute_betas_gwr(temp_y, temp_X, w.reshape((-1, 1)))[0]\n",
    "                    #print(beta)\n",
    "                    yhat = np.dot(temp_X, beta)\n",
    "                    new_XB[:, j] = yhat.flatten()\n",
    "                    err = (temp_y - yhat).reshape((-1, 1))\n",
    "                    params[j, :] = beta[0][0]\n",
    "                    \n",
    "                num = np.sum((XB-new_XB)**2)\n",
    "                den = 1 + np.sum(np.sum(XB, axis=1)**2)\n",
    "                score = (num / den)\n",
    "                XB = new_XB\n",
    "        \n",
    "                scores.append(deepcopy(score))\n",
    "                delta = score\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"Current iteration:\", iters, \",SOC:\", np.round(score, 8))\n",
    "                if delta < tol:\n",
    "                    break\n",
    "\n",
    "        return params, X, sig\n",
    "    \n",
    "    #local scoring - outer loop \n",
    "    while crit > 1e-8:\n",
    "        mu = np.exp(eta).reshape((-1, 1))\n",
    "        w = mu.reshape((-1,1))\n",
    "        z = eta + ((y.reshape((-1, 1)) - mu) / mu)\n",
    "        betas, X, sigma = backfit(z, X, w, v2, X_df, pid, geomap,is_Spatial, verbose)\n",
    "        s_new = np.multiply(betas.T, np.log(X))\n",
    "        inner = np.sum((s_old - s_new)**2, axis=1)\n",
    "        num = np.sum(w*inner)\n",
    "        den = np.sum(w*np.sum((1 + s_old)**2, axis=1).reshape((-1, 1)))\n",
    "        crit = num / den\n",
    "        eta = np.sum(s_new, axis=1).reshape((-1, 1))\n",
    "        s_old = s_new\n",
    "        \n",
    "    return betas, eta, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-camel",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "three-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "austria = pd.read_csv('Data/austria.csv')\n",
    "austria_shp = gp.read_file('Data/austria.shp')\n",
    "Dja = austria['Dj'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "processed-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "austria = austria[austria['Origin'] != austria['Destination']]\n",
    "flows = austria['Data'].values \n",
    "Oi = austria['Oi'].values \n",
    "Wj = austria['Dj'].values \n",
    "Dij = austria['Dij'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "incoming-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = austria.copy()\n",
    "X_df['Code'] = X_df['Origin'] + X_df['Destination']\n",
    "X_df = X_df.loc[:, ~X_df.columns.str.contains('^Unnamed')]\n",
    "X_df = X_df[['Code','Origin', 'Destination', 'Data', 'Oi', 'Dj', 'Dij']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "seeing-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "Aij = SpatialSmooth(5, X_df, 1, austria_shp, -1.35)\n",
    "X = np.column_stack((Oi, Wj, Dij, Aij))\n",
    "w = np.ones(72).reshape((-1,1))\n",
    "betas = iwls(flows.reshape((-1,1)), np.log(X), family=Poisson(), offset=w.reshape((-1, 1)), y_fix=None, wi=w.reshape((-1, 1)))[0]\n",
    "f = np.exp(np.dot(np.log(X), betas) + np.random.normal(0, .0001, (72,1))).reshape((-1,1))\n",
    "betas_cd, eta_cd, sigma_cd = CompeteDestination(f, 4, 5, 6, X_df, 1, austria_shp, is_Spatial=True, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "medieval-surveillance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas_iwls:\n",
      "[[ 0.71369558]\n",
      " [ 0.72409961]\n",
      " [-1.0584376 ]\n",
      " [-0.08370744]]\n",
      "betas_cd:\n",
      "[[ 0.7137392 ]\n",
      " [ 0.7241024 ]\n",
      " [-1.05849506]\n",
      " [-0.08372059]]\n",
      "sigma_cd:\n",
      "-1.35\n"
     ]
    }
   ],
   "source": [
    "print('betas_iwls:', betas, 'betas_cd:', betas_cd,'sigma_cd:', sigma_cd, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-brighton",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
